{
    "title": "Will human consciousness ever be transferable to a new body or a machine (e.g. a robot, cyborg, computer, or avatar)? Can you transfer your own consciousness and memory and leave your biological body without creating two selves? - Quora",
    "tags": [
        "Posthumanism",
        "Mind Uploading",
        "Cyborgs",
        "Science Behind Science Fiction",
        "Transhumanism",
        "Consciousness"
    ],
    "response": [
        {
            "author_info": {
                "name": "Mitch Ratcliffe",
                "href": "/profile/Mitch-Ratcliffe"
            },
            "answer_text": "We may, with massively increased computing power and the introduction of a very broad range of sensory IO capabilities, someday be able to model the brain of an embodied mind, but we will accomplish only the model of a \"consciousness\" and not a fully realized conscious being. Transferring a human consciousness into that \"body\" will produce something not-human and, I suspect, more like a recording or parody of a conscious being than a \"person.\"  Of course, at that point, we will have to argue whether the model is a superset or subset of conscious activity. My reading of Chalmers, Damasio, Searle and many others leads me to believe that a computational model of consciousness will never be comparable to human consciousness, except on a capacity basis, such as the capacity to play chess. Many capacities do not add up to subjective being. ADDING to the response: I responded to Justin Golden below, but the comment doesn't seem to be visible, so here it goes: Speaking as a bionic person, I think you are making a very poor argument. I have artificial discs in my cervical spine that were impossible to build even a decade ago -- and that won't be on the market for another five years. Physical systems are immensely difficult to manufacture, and there is no universally recognized definition of what a consciousness is to rival physical laws on which artificial biological systems must be built. Ray Kurzweil may be famous, but that doesn't make him right, nor does exponential advances in technology assure success in this venture, because the complexity of consciousness, separate from the effort of building a mechanical environment that could host consciousness, may be a barrier to transferring consciousness. If, because of the multi-dimensional nature of consciousness, as it is a sum and a product of many inputs and storage/data transfer modalities, it may be the case that no computational system could be built to store a particular mind's consciousness without extensive individual modification of the machine's architecture. In other words, consciousness may be so complex that it can't run on a computational system that isn't a unique replica of the mind in which it emerged. That would make the economics of consciousness transference almost unimaginably expensive. Since there would be no test environment, as consciousness could not be stored in anything other than a compatible consciousness machine, the potential for errors that would corrupt a transferred consciousness is astronomically high, as well, since there would be no backup. Even if it could be built, the failure of the machine to meet the needs of a specific consciousness is likely to prevent this from ever being feasible. It is also not clear that a static system could accommodate consciousness. Since, as Damasio argues, much of the activity of the brain and mind is a mapping of the body, which also contributes to the metaphorical physicality of language, as George Lakoff documented in several excellent studies, a great deal of computational capacity may need to be dedicated to fooling the consiousness into thinking it has a body in order for its humanity to remain. One may constantly need to upgrade or reengineer a consciousness machine, which would contribute to its prohibitive expense. One may simply find that a human consciousness, finding itself implanted in a non-human body, with a different mapping entirely, would become vegetative, deeply psychotic or just simply break from the stress of being disembodied. Even if you disagree with Thomas Nagel's argument about the specific nature of consciousness in different bodies in his \"What is it like to be a bat?\" can you seriously argue that a bat consciousness would be functional in a squirrel's body, or that, implanted in a human body, the bat's consciousness could be enlarged to make use of the new capacities it found in its new home? For those of you arguing consciousness is simply a mechanical-physical process, a modern version of the most simplified monism, consider that even the simplest software does not transfer reliably from one computational \"body\" to another without fragility due to differences in OS at the grossest level, or configuration of the hardware and conflicts with processes that were not present in previous systems capturing and not releasing resources. Finally, except for someone who was very ill, given the chances of dying from this transference being so high, it is far more likely that we will focus on prolonging human life than it is that human consciousness transference will be a viable path. And, just for the heck of it, adding my response to Mark Harrison's more compelling argument:  I think you rely on a fallacy in arguing from the continuity of the consciousness in a body slowly being replaced by mechanical prosthetics. Let's call it the Steve Austin Fallacy or, better, the Lee Majors Fallacy, since everyone knows his character's bionic character was full of human compassion despite his machine parts. You assume there is no impact from the gradual replacement of the organs of the brain, relying on the familiar argument that a robotic body is body-like. Gradual replacement of parts of the brain, whenever it might take place, is not the same as transferring a consciousness to a machine environment. Optical processing may be replicable by a machine, but it may be like having an artificial leg, which may perform beautifully but provides its user few of the physical experiences delivered by a leg of flesh. Granted for example that a partially brained person, a hydranencephelic child, who has no higher brain components than the brain stem, can demonstrate mindful behaviors, such as reflexes and laughter, but that does not mean if you inserted a computational replacement of the cerebral cortex, thalamus and other structures, that the child would suddenly have a whole consciousness. If you transferred an existing consciousness into that part-hydranencephelic part-computer brain, would that new consciousness be complete. Might it not, given the existing patterns of the hydranencephilic's mind, find its lower brain functions to be incompatible with a \"normal\" brain within a human body? To the same degree that you dismiss Roger Penrose's quantum consciousness hypothesis for lack of evidence -- some evidence for which may at least have been demonstrated logically by Ludvik Bass in The Mind of Wigner's Friend, although I believe his argument is flawed, as well -- you must dismiss for lack of evidence your argument that replacing brain components one piece at a time would not destroy the consciousness, because it hasn't been done. Scientists may be able to interface silicon and neuron, they may be able to manipulate a single neuron with a laser, but there's no evidence that these neurons produce the same experience that a neuron in a complex brain structure does. It may fire, but that firing, absent the wash of chemicals the brain relies on to help modulate signaling, may not be like a brain's neuronal firing. Given the complete lack of rules of consciousness comparable to the laws of physics, which are also incomplete, it isn't possible to dismiss skeptics who question whether consciousness is transferrable without concurrently dismissing the argument that it is inevitable. And while I agree with you that there is the chance it could happen someday, the practical challenges of transferring consciousness, even if not physically prohibitive, may be economically impossible. ",
            "date": "Updated January 19, 2011",
            "views": "127",
            "upvotes": " View 35 Upvoters",
            "upvoters": [
                {
                    "user_id": "Sebastian Michaelis",
                    "user_href": "/profile/Sebastian-Michaelis-162"
                },
                {
                    "user_id": "Cain Chiles",
                    "user_href": "/profile/Cain-Chiles"
                },
                {
                    "user_id": "Nitya Joshi",
                    "user_href": "/profile/Nitya-Joshi-11"
                },
                {
                    "user_id": "Nigael Larcot",
                    "user_href": "/profile/Nigael-Larcot"
                },
                {
                    "user_id": "Asdf Fasdf",
                    "user_href": "/profile/Asdf-Fasdf-4"
                },
                {
                    "user_id": "Jman Richards",
                    "user_href": "/profile/Jman-Richards"
                },
                {
                    "user_id": "Michael Trinastic",
                    "user_href": "/profile/Michael-Trinastic"
                },
                {
                    "user_id": "Kalyan Vadrevu",
                    "user_href": "/profile/Kalyan-Vadrevu-1"
                },
                {
                    "user_id": "Ravi Teja Tata",
                    "user_href": "/profile/Ravi-Teja-Tata"
                },
                {
                    "user_id": "Shane Luckie",
                    "user_href": "/profile/Shane-Luckie"
                }
            ]
        },
        {
            "author_info": {
                "name": "Paul King",
                "href": "/profile/Paul-King-2"
            },
            "answer_text": "This is not theoretically impossible, so it seems likely to happen eventually, however the way it happens may be different from what people expect. The idea of consciousness being transferred into computers is typically portrayed in one of two ways: In sci-fi movies, conscious identity is \"extracted\" (somehow) from the brain and \"injected\" into a computer that has a capacity for conscious emulation.In philosophical thought experiments and in the singularity community it is imagined that eventually brain scanning will be so detailed that the entire brain down to every neuron, synapse, and receptor can be scanned and simulated brute-force in a giant computer.It seems unlikely that either of these will ever happen. The sci-fi approach relies too much on magic, and the simulation approach requires enormous sophistication, scanning access, and computational capacities. If it's possible, it seems at least 100 years away. But there is another way. Current models of consciousness suggest that consciousness, and neural processing in the brain generally, is a decentralized adaptive process. If true, consciousness could be transferred to a computer incrementally via adaptation. As an analogy, consider the marketing/PR team working at a Fortune 1000 corporation. The marketing team puts out a coherent message -- the voice of the company -- but this is created by a team of people who collaborate and synthesize their thinking into a consistent framework. New people join the marketing department all the time, and they learn the ropes and take over from people who leave. Every few years, everyone working there is new, but the voice of the company (its identity, messages, and memory) remain intact. Now suppose robots were rotated into the marketing department. Over time, the marketing identity of the company would be fully run by robots. In the case of the brain, with neural prosthesis and brain-machine interfaces, it is possible that a clever computer could become quite integrated into the brain in support of memory, enhanced perception, and even enhanced thought. Such a machine might adapt and support neural activity to such an extent that it becomes better at it than the brain. Eventually it doesn't really need its biological half, and could operate just fine without it, carrying the identity of the former biological brain owner forward. ",
            "date": "Updated December 25, 2015",
            "views": "1184",
            "upvotes": " View 580 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Joshua Flores",
                    "user_href": "/profile/Joshua-Flores-245"
                },
                {
                    "user_id": "M. Steven",
                    "user_href": "/profile/M-Steven-5"
                },
                {
                    "user_id": "Cain Chiles",
                    "user_href": "/profile/Cain-Chiles"
                },
                {
                    "user_id": "Matt Ali",
                    "user_href": "/profile/Matt-Ali-10"
                },
                {
                    "user_id": "Austin Snyder",
                    "user_href": "/profile/Austin-Snyder-49"
                },
                {
                    "user_id": "Nitya Joshi",
                    "user_href": "/profile/Nitya-Joshi-11"
                },
                {
                    "user_id": "Caleb Budde",
                    "user_href": "/profile/Caleb-Budde"
                },
                {
                    "user_id": "Steve Batra",
                    "user_href": "/profile/Steve-Batra"
                },
                {
                    "user_id": "William Harris",
                    "user_href": "/profile/William-Harris-11"
                },
                {
                    "user_id": "Nigael Larcot",
                    "user_href": "/profile/Nigael-Larcot"
                }
            ]
        }
    ]
}