{
    "title": "What is the next step beyond deep learning in AI? - Quora",
    "tags": [
        "Artificial Neural Networks",
        "Deep Learning",
        "Artificial Intelligence"
    ],
    "response": [
        {
            "author_info": {
                "name": "Ajit Rajasekharan",
                "href": "/profile/Ajit-Rajasekharan"
            },
            "answer_text": "Asked to answer... My understanding is too shallow to speculate on what is beyond deep learning, other than to cite a paper published in Science yesterday (Dec 11 2015) that perhaps gives a glimpse of what may be coming after deep learning. The paper describes a computational model with ability to produce a variation of a character in an unfamiliar writing system, on the first try, that is indistinguishable from that of humans.  Specifically, the paper  introduces a Bayesian program learning framework capable of  Learning with few samples of data unlike current deep learning models that require huge sets of training data creative generalization capabilites that are in many cases indistinguishable from humans Figure from Human-level concept learning through probabilistic program induction, 11 Dec 2015, Science Three core principles analyzed in the paper are   Compositionality, which is the idea that representations are built up from simpler primitives. Causality, which is that the model represents the abstract causal structure of how characters are generated. Learning to learn,  this idea that knowledge of previous concepts can help support the learning of new concepts. Given these principles are relatively general, the authors claim, they can not only apply to characters, but  to many other types of concepts (although this remains to be seen). In the approach described in this paper, concepts are represented as simple probabilistic programs - that is, probabilistic generative models expressed as structured procedures in an abstract description language. [4], [3],  [5]  Figure from Human-level concept learning through probabilistic program induction, 11 Dec 2015, Science  Figure from Human-level concept learning through probabilistic program induction, 11 Dec 2015, Science References Computer system passes \u201cvisual Turing test\", MIT News, 10 Dec 2015Human-level concept learning through probabilistic program induction, 11 Dec 2015, ScienceProbabilistic machine learning and artificial intelligence, May  2015, Nature  The Conceptual Mind: New Directions in the Study of Concepts: Eric Margolis, Stephen Laurence: 9780262028639: Amazon.com: Books Probabilistic Models of Cognition ",
            "date": "Answered December 13, 2015",
            "views": "109",
            "upvotes": " View 32 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Kuldeep Ghildiyal",
                    "user_href": "/profile/Kuldeep-Ghildiyal-2"
                },
                {
                    "user_id": "Philippe Bouaziz (Data Scientist/PhD)",
                    "user_href": "/profile/Philippe-Bouaziz-Data-Scientist-PhD"
                },
                {
                    "user_id": "Sidd Sahay",
                    "user_href": "/profile/Sidd-Sahay"
                },
                {
                    "user_id": "Rohan Majumdar",
                    "user_href": "/profile/Rohan-Majumdar"
                },
                {
                    "user_id": "Josh Nursing",
                    "user_href": "/profile/Josh-Nursing"
                },
                {
                    "user_id": "Tauseef Hussain",
                    "user_href": "/profile/Tauseef-Hussain-5"
                },
                {
                    "user_id": "Travis Millman",
                    "user_href": "/profile/Travis-Millman"
                },
                {
                    "user_id": "Truong Nguyen",
                    "user_href": "/profile/Truong-Nguyen-4"
                },
                {
                    "user_id": "Chaz Tikov",
                    "user_href": "/profile/Chaz-Tikov"
                },
                {
                    "user_id": "Bilwaj K Gaonkar",
                    "user_href": "/profile/Bilwaj-K-Gaonkar"
                },
                {
                    "user_id": "Aditya Arun",
                    "user_href": "/profile/Aditya-Arun"
                },
                {
                    "user_id": "Cole Fun",
                    "user_href": "/profile/Cole-Fun"
                },
                {
                    "user_id": "Sarnath K",
                    "user_href": "/profile/Sarnath-K"
                },
                {
                    "user_id": "Vikas Goyal",
                    "user_href": "/profile/Vikas-Goyal-18"
                },
                {
                    "user_id": "Nolan Amano",
                    "user_href": "/profile/Nolan-Amano"
                },
                {
                    "user_id": "Peicheng Zou",
                    "user_href": "/profile/Peicheng-Zou"
                },
                {
                    "user_id": "Georgios Mavrakis",
                    "user_href": "/profile/Georgios-Mavrakis"
                },
                {
                    "user_id": "Magnus Snorrason",
                    "user_href": "/profile/Magnus-Snorrason"
                },
                {
                    "user_id": "Gonzalo Benegas",
                    "user_href": "/profile/Gonzalo-Benegas-1"
                },
                {
                    "user_id": "Gary Wang",
                    "user_href": "/profile/Gary-Wang-57"
                }
            ]
        },
        {
            "author_info": {
                "name": "Chomba Bupe",
                "href": "/profile/Chomba-Bupe"
            },
            "answer_text": "In order to discuss about the next \"big thing\" to replace deep learning it might be necessary to look at what AI is and how much deep learning has achieved and it's shortcomings. AI aims to build intelligence in machines so that other intelligent agents i.e humans can perceive them as intelligent. We humans must judge and conclude that the said system is truly intelligent by any measure of intelligence. We normally judge intelligence as the ability to learn from examples or experiences with minimal supervision, usually by interactions with the environment or other intelligent agents. Like a child would learn a new language with minimal supervision together with other complex tasks like navigating through the environment. The ability to successfully learn a new task and generalize it to other otherwise unrelated tasks is a very good indicator of intelligence. Deep learning is itself a revolutionary idea from its humble beginnings in the 80's to it becoming a state-of-the-art learning algorithm today, it has undergone many changes and has achieved a lot. Deep learning has out performed many traditional algorithms in areas such image classification, natural language understanding, speech recognition and many more. Deep learning does show some intelligence in the sense that it can generalize remarkably very well but only when the tasks are related. It is hard for the system to transfer its learnt representation to other unrelated tasks. One thing deep learning is very good at is mapping. Deep learning literally only learns to map a high dimensional vector to another output vector with some tolerance to certain transformations. But it doesn't do the following very well. One-shot learning: Deep learning is clearly not a one-shot learner. Deep learning requires a lot of training data due to the large amount of parameters needed to be tuned. One-shot learning is true intelligence as observed in humans ability to learn from few examples.Extracting meaning: For example the output layer just gives a score showing which classes are present and nothing else. It doesn't extract geometric meaning or usage meaning. Perhaps a better example is in grammar, if I ask a talking robot \"can you get me something I can drink from?\" or \"can you get me a cup?\" how can it respond? the two statements have the same meaning. This example might not be a better example but it is clear that there are many ways of saying the same thing as evident in human-to-human conversations. Meaning is hard to define but it involves finding relationships between unrelated events or tasks sort of like a knowledge graph.Unsupervised learning: most of deep learning architectures like convolutional neural networks are supervised learning models. Much of true AI is based on unsupervised learning models. To learn with minimal supervision is a good sign of intelligence like most humans can learn complex stuff without supervision.Flexibility: Deep learning is cumbersome requiring high-end machines in order to learn large models. Once the system learns it becomes rigid plus it's functionality is limited only to the tasks it learnt. You do notice that a fruit fly or an ant has just about 250K neurons but it's brain exhibits a multitude of functionalities compared to current large scale state-of-the-art deep neural nets.Thus my argument here is that whatever will have to replace deep learning must obviously do well in the above mentioned points and in addition to the following points: Computational efficiency: I believe the deep neural architecture is too naively implemented. The neurons in the biological brains are clearly not always active. There must be a way in which computations can be sped up by utilizing sparsity in the nature of neural activation patterns not just by using GPUs. Thus signal propagation through the network would be directed to the right network regions, sort of like divide and conquer hence speeding things up further.One-shot learner: usually such a system can be realized by extracting meaningful atomic representations or components in the training signals so that when a new signal is encountered the system would guess correctly. Unlike deep learning the learnt components maybe learnt in a single layer and may be more meaningful.Incremental learner: learning never stops in humans, we are always learning at a conscious and sub-conscious level. A true AI system needs to have the ability to learn continuously. This is important in cases such as robotic applications.Knowledge transfer: Learning one task improves a previously learnt unrelated task. This is a concept of knowledge transfer and can result in novel and totally new idea generation processes such as in art and music whereby machines would produce what we people call \"works of art\". The ability to transfer knowledge is actually necessary for one-shot learning. This is a very important concept in machine learning but hard to realize in reality.There is a lot that needs to be done in AI to truly realize intelligence in machines. Deep learning maybe the current state-of-the-art but doesn't mean it's here to stay. In addition to what has been said already there are a lot of issues with deep learning that makes it incapable in some setups. Future algorithms will probably try to mimic more of the way humans solve problems rather than trying to emulate the brain neurons. Like airplanes don't flap wings, sometimes mimicking exact biological systems might not be the best approach to building a real AI system. There might be other motivations as to why biological neurons are structured the way they are other than for computational reasons alone. Hope this helps. ",
            "date": "Updated September 27, 2016",
            "views": "316",
            "upvotes": " View 123 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Shashank Shekhar",
                    "user_href": "/profile/Shashank-Shekhar-134"
                },
                {
                    "user_id": "Eric Jang",
                    "user_href": "/profile/Eric-Jang"
                },
                {
                    "user_id": "Michael P",
                    "user_href": "/profile/Michael-P-87"
                },
                {
                    "user_id": "Quora User",
                    "user_href": "/profile/Jeff-Z-44"
                },
                {
                    "user_id": "Anvesh Reddy",
                    "user_href": "/profile/Anvesh-Reddy-70"
                },
                {
                    "user_id": "Alp Erer",
                    "user_href": "/profile/Alp-Erer"
                },
                {
                    "user_id": "Chinlock Oh",
                    "user_href": "/profile/Chinlock-Oh"
                },
                {
                    "user_id": "Thomas Jalabert",
                    "user_href": "/profile/Thomas-Jalabert"
                },
                {
                    "user_id": "Gilles Malfreyt",
                    "user_href": "/profile/Gilles-Malfreyt"
                },
                {
                    "user_id": "William Profit",
                    "user_href": "/profile/William-Profit"
                }
            ]
        },
        {
            "author_info": {
                "name": "Christopher Albertson",
                "href": "/profile/Christopher-Albertson-3"
            },
            "answer_text": "Of course no one knows the future but we can say what the \u201cnext big thing\u201d has to DO. But we can\u2019t say how it will work. I think deep learning works because it has more layers of abstraction than a shallower network. No magic it is that simple. But you can\u2019t just keep piling on hidden layers. For lots of both practical and theoretical reasons. The next big thing will allow many more layers but using other methods. My guess is that we will build systems of deep networks. Like a network is made of many \u201cperceptrons\u201d organized is a semi-regular way the bigger system will use multile networks organized in rather complex, non regular ways. I think this is how the bran works. There are sections of it that have different kinds of mostly regular arrays of cells but the sections are organized in a complex say. This next step will be HARDER because it is not accomplish by simply tossing in tons of really fast hardware. We will have to figure out how one network provides feedback and \u201ctraining\u201d to another in some kind of cyclic self referencing system. \u201cTheory of Mind\u201d will again become a serious research topic. But in the means time wee can build really good pattern classifiers and make even better suggestion about who shoppers should buy and better stock market predictions and so on. Good reading for the \u201cnext big thing\u201d is Minsk\u2019s \u201cSociety of Mind\u201d. Minsky had no clue how to implement his ideas but his \u201csociety\u201d idea has good. The brain is NOT just a big network, It is hundreds in independent subparts that all work together and sometime compete. ",
            "date": "Answered June 10, 2017",
            "views": "11",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Suraj Srinivas",
                "href": "/profile/Suraj-Srinivas"
            },
            "answer_text": "TLDR; Learning to Reason with data. Deep learning - at least in it's current form -  is all about learning complicated functions of the input (image/sentence). The next step is to learn an algorithm instead of a function to perform the mapping.  What's the difference, you ask? An algorithm can also perform iterative or recursive computations, whereas any complicated function can only perform the equivalent of branching statements (if-else, switch) and arithmetic/logical operations. Many researchers think that this is the next big step in AI - something which can possibly enable machines to perform reasoning.  As an example, consider the following set of sentences.   This example is from the paper [1410.3916] Memory Networks . It should be obvious that any complicated function cannot answer questions like these in general. In theory, Recurrent Neural Networks (RNNs) can approximate any algorithm in the way that Feedforward Neural Networks can approximate any function. However, in practice, they do not seem to remember things for a long time. Recent works like Neural Turing Machines and Memory Networks are steps in the right direction. They are recurrent models with potentially unbounded memory - something which can give them the ability to remember a lot of things. This is a hot area of research right now - and I suspect something big will come of this in the next 5-6 years at least. These are exciting times for AI!    ",
            "date": "Answered December 13, 2015",
            "views": "43",
            "upvotes": " View 25 Upvoters",
            "upvoters": [
                {
                    "user_id": "Hugues Talbot",
                    "user_href": "/profile/Hugues-Talbot"
                },
                {
                    "user_id": "Kr Pawan Pandit",
                    "user_href": "/profile/Kr-Pawan-Pandit"
                },
                {
                    "user_id": "Martha De Luque",
                    "user_href": "/profile/Martha-De-Luque-1"
                },
                {
                    "user_id": "Alexander Ryndin",
                    "user_href": "/profile/Alexander-Ryndin"
                },
                {
                    "user_id": "Tauseef Hussain",
                    "user_href": "/profile/Tauseef-Hussain-5"
                },
                {
                    "user_id": "Prithvi Srinivasan",
                    "user_href": "/profile/Prithvi-Srinivasan"
                },
                {
                    "user_id": "Ambert Ho",
                    "user_href": "/profile/Ambert-Ho"
                },
                {
                    "user_id": "Bilwaj K Gaonkar",
                    "user_href": "/profile/Bilwaj-K-Gaonkar"
                },
                {
                    "user_id": "Arshdeep Singh",
                    "user_href": "/profile/Arshdeep-Singh-1"
                },
                {
                    "user_id": "Faizan Shaikh",
                    "user_href": "/profile/Faizan-Shaikh-13"
                }
            ]
        },
        {
            "author_info": {
                "name": "Chris Nicholson",
                "href": "/profile/Chris-Nicholson-1"
            },
            "answer_text": "A2A. There are several good answers here. Ajit Rajasekharan was right to bring up the recent paper in Science. BLP requires much less data than deep artificial neural networks, and that's important, because ANNs are approaching 100% accuracy on some narrow problem sets. So the only way to move forward would be to find a more efficient solution. It looks like BLP does that for images, so now we'll have to see if it generalizes well to other data types.  Suraj Srinivas was right to bring up reasoning. Geoff Hinton has spoken repeatedly about something he calls \"thought vectors\", or a distributed representation of an idea that could prompt a chat bot to respond with another idea. This is one approach people are taking when building conversational agents. It's just that the possibilities and recombinations of conversation are so large that we need a lot more processing power. Finally, while we are making rapid progress solving narrow problems, a more general solution will need to know *which* algorithm to choose to handle the complexity and noise that the world throws at it.  Chomba Bupe is right to say we should look at the history of AI. The advances in AI that we see today are the result of old algorithms being adapted to much more powerful hardware. There are doubtless other ideas just waiting to be realized with the next generation of chips. ",
            "date": "Answered December 16, 2015",
            "views": "56",
            "upvotes": " View 11 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Faizan Shaikh",
                    "user_href": "/profile/Faizan-Shaikh-13"
                },
                {
                    "user_id": "Cole Fun",
                    "user_href": "/profile/Cole-Fun"
                },
                {
                    "user_id": "Will Heng",
                    "user_href": "/profile/Will-Heng"
                },
                {
                    "user_id": "Lucktroy Zhang",
                    "user_href": "/profile/Lucktroy-Zhang"
                },
                {
                    "user_id": "Chomba Bupe",
                    "user_href": "/profile/Chomba-Bupe"
                },
                {
                    "user_id": "Infinity Puer",
                    "user_href": "/profile/Infinity-Puer"
                },
                {
                    "user_id": "Eduardo Coltre Ferraciolli",
                    "user_href": "/profile/Eduardo-Coltre-Ferraciolli"
                },
                {
                    "user_id": "Ajit Rajasekharan",
                    "user_href": "/profile/Ajit-Rajasekharan"
                },
                {
                    "user_id": "Mohammed Helal",
                    "user_href": "/profile/Mohammed-Helal-2"
                },
                {
                    "user_id": "Tom Flores",
                    "user_href": "/profile/Tom-Flores-3"
                },
                {
                    "user_id": "Judith Pletcher",
                    "user_href": "/profile/Judith-Pletcher"
                }
            ]
        },
        {
            "author_info": {
                "name": "Jan Krikke",
                "href": "/profile/Jan-Krikke"
            },
            "answer_text": "Good technical answers have already been given (among them by Chomba Bupe), but we should take into account that AI is not some distant technology but already widely applied. The next step beyond deep learning will include \"broad application.\" For broad application, it is useful to keep an eye on China. The Chinese are not ignoring research but they are very pragmatic about application. China is the factory of the world. Chinese companies make many of the electronics that are used in the actual application of AI. Moreover, China has 1.4 billion people. Having extensive data on 1.4 billion people and being the factory of the world is a powerful combination. Using economies of scale, Chinese companies may develop \"off-the-shelf\" AI systems to be used in the hardware they produce. An example is Chinese elderly care robots. These robots can be given wireless upgraded with additional \"knowledge\" as AI advances. Inside China\u2019s experiment to find friends for 230 million old people ",
            "date": "Answered August 24, 2018",
            "views": "281",
            "upvotes": " View 1 Upvoter",
            "upvoters": [
                {
                    "user_id": "Rugal Dourandi",
                    "user_href": "/profile/Rugal-Dourandi"
                }
            ]
        },
        {
            "author_info": {
                "name": "Michael Miller",
                "href": "/profile/Michael-Miller-22"
            },
            "answer_text": "Integration of AI techniques into a viable cognitive architecture.  This research has already begun, it's just not as sexy as beating humans at video games. The deep learning folks know that they have action selection and classification and even conceptual clustering down, but they don't have reasoning, and quite a few other characteristics of intelligence yet.  ",
            "date": "Answered December 12, 2015",
            "views": "2",
            "upvotes": " View 8 Upvoters",
            "upvoters": [
                {
                    "user_id": "Dinesh Prajapati",
                    "user_href": "/profile/Dinesh-Prajapati-148"
                },
                {
                    "user_id": "Faizan Shaikh",
                    "user_href": "/profile/Faizan-Shaikh-13"
                },
                {
                    "user_id": "Chansa Kabwe",
                    "user_href": "/profile/Chansa-Kabwe"
                },
                {
                    "user_id": "Ankit Devani",
                    "user_href": "/profile/Ankit-Devani"
                },
                {
                    "user_id": "Michal Illich",
                    "user_href": "/profile/Michal-Illich"
                },
                {
                    "user_id": "Ajit Rajasekharan",
                    "user_href": "/profile/Ajit-Rajasekharan"
                },
                {
                    "user_id": "Alexander Ororbia",
                    "user_href": "/profile/Alexander-Ororbia"
                },
                {
                    "user_id": "Mustafa Ihssan",
                    "user_href": "/profile/Mustafa-Ihssan"
                }
            ]
        },
        {
            "author_info": {
                "name": "Murugesan Vadivel",
                "href": "/profile/Murugesan-Vadivel"
            },
            "answer_text": "There are many things in Deep learning itself like End-to-end learning and much more complex networks like Highways networks, link networks and much more, but to say at a whole, deep learning (Neural Networks) will be replaced by cognitive modeling in which Neural science is one of the part among psychology, philosophy, anthropology, linguistics and General AI. ",
            "date": "Answered May 21, 2017",
            "views": "503",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Christian Ramsey",
                "href": "/profile/Christian-Ramsey-10"
            },
            "answer_text": "DEEP Reinforcement Learning. Reinforcement learning is the future of artificial general intelligence. Reinforcement learning gives neural networks a \u201cbody\u201d or a sensory apparatus. in a virtual 3d world. These algorithms will help machines achieve general intelligence. Deep learning is \u201cjust\u201d perception. ",
            "date": "Answered July 17, 2017",
            "views": "349",
            "upvotes": "0"
        }
    ]
}