{
    "title": "When, how and why was the synthesizer invented? - Quora",
    "tags": [
        "Music Technology",
        "Synthesizers",
        "Speech Synthesis",
        "Electronic Music"
    ],
    "response": [
        {
            "author_info": {
                "name": "Rodney Jones",
                "href": "/profile/Rodney-Jones-23"
            },
            "answer_text": "Phew, that\u2019s a big ask\u2026  The \u2018Why\u2019 is perhaps the easiest to answer: whether you love or hate Musique Concrete and the compositions of people like Steve Reich, Karlheinz Stockhausen, Terry Riley, etc., experimental musicians have been pushing the envelope of sound generation for more than 100 years. Their collaborations with electronics engineers resulted in devices such as the Theremin, the Ondes Martinot and the Trautonium in the 1920\u2019s, and the Ondeolin and Claviolin in the 1940\u2019s. Not synthesisers in the accepted sense, but clearly their sounds were produced non-acoustically, ergo, synthetically. I\u2019m not sure of the accepted etymology of the word synthesiser (synthesizer in the US), but I guess in most peoples heads, the word started to be used to describe the work done in the 1960\u2019s by Bob Moog and Don Buchla in the USA, and Peter Zinovieff (EMS) in the UK. Later innovators include Alan Pearlman (ARP), Dave Smith (Sequential Circuits) and John Simonton (PAiA) Most of the electronic building blocks of the synthesiser (oscillators, amplifiers, filters, ring modulators, etc.) existed well before this, but the real revolution was when Moog and Buchla independently started to use voltage control, whereby these same building blocks could now be thought of as modules, giving way to a flexible architecture. Each module had a \u2018control\u2019 input and/or a \u2018signal\u2019 (ie. Audio) input; and all had an output. However, the beauty of the modular architecture was that the distinction between control and signal could be blurred. For example, the output of an oscillator is conventionally thought of as a tone in the audio spectrum. However this tone could be fed into the control input of another oscillator\u2026 if the frequency is low, the result is frequency modulation like vibrato. If the frequency is high, the result can be a harmonically complex waveform. To facilitate this architectural flexibility, the modules could be connected in various ways, with Moog and Buchla preferring external \u2018patch wires\u2019 and EMS the \u2018routing matrix\u2019. However most production synthesisers chose to hard wire the modules in a configuration mostly suited to imitative synthesis (organs, pianos, brass, strings, etc.) rather than the more \u2018avant garde\u2019 (bizarre?) sounds preferred by the experimental musicians. So the \u2018Why\u2019 is already covered. The \u2018When\u2019\u2026 I\u2019ll go for early sixties. And the \u2018How\u2019 is mostly evolution, punctuated with moments of revolution. ",
            "date": "Answered December 3, 2016",
            "views": "299",
            "upvotes": " View 2 Upvoters",
            "upvoters": [
                {
                    "user_id": "Brandon Perryman",
                    "user_href": "/profile/Brandon-Perryman-5"
                },
                {
                    "user_id": "Zeibura S. Kathau",
                    "user_href": "/profile/Zeibura-S-Kathau"
                }
            ]
        },
        {
            "author_info": {
                "name": "Zeibura S. Kathau",
                "href": "/profile/Zeibura-S-Kathau"
            },
            "answer_text": "Ah, this is one of those questions which is hotly debatable depending on your definition of what a synthesizer is. First let me share this quote from Ishkur\u2019s Guide to Electronic Music which perfectly satirises the nature of this debate: The real inventor of electronic music was Grog, who in 65,000 BC started banging his stick against a rock in a rhythmic, synchronous repetetitetitetive motion, thereby producing the first tribal track. And what, pray tell, is so electronic about that? Well... he was struck by lightning at the time. It really gave an analogue warmth and fullness to his sound. The \u201cwhen\u201d and by extension the \"how\" don\u2019t have a universally accepted right answer, neither about electronic music and nor about its bread and butter, the synthesizers themselves. The reason is\u2026 well, semantics. Let\u2019s continue exploring this question in the Oxford English dictionary: Synthesizer (n.) An electronic musical instrument, typically operated by a keyboard, producing a wide variety of sounds by generating and combining signals of different frequencies. Here\u2019s the catch - \u201csynthesizer\u201d, as you might infer by that rather narrow and technical definition, is a recent word, however \u201csynthesis\u201d has a more generic meaning - \u201ccombining two simple things to make a more complex thing.\u201d It can be used in other fields than music. And by that extremely broad definition, a 12-string guitar, a church organ and a piano are all examples of \u201csound synthesis\u201d, as they all create their tones by combining more than one sound source! Which is clearly wrong, since no one would ever really consider piano tuning to be \u201cadditive synthesis\u201d just because there\u2019s more than one string on each key. So let\u2019s move onto the \u201cwhy\u201d, which is easier to take a stab at. The earliest ideas for \u201csynthesizers\u201d were speech synthesizers rather than musical instruments. Speech synthesis, which in its broad sense just means combining sound sources to artificially emulate the human voice, predates electronic music and even electroacoustics, so the first speech synthesizers were not electronic, but simple mechanical instruments. Examples are Wolfgang von Kempelen's Speaking Machine, which was as early as 1769, and Josef Faber\u2019s Euphonia:  Even if you fast forward to the 20th century, you find that the term \u201celectronic music\u201d didn\u2019t appear in print to refer to a type of music until 1949, in a publication written by Werner Meyer-Eppler, a pioneering phoneticist and speech synthesis expert who went on to co-found the Cologne electronic music studio and greatly influenced Karlheinz Stockhausen. History tells us rather emphatically that synthetically emulating human voices seemed to be of primary importance to us over creating synthetic musical instruments. Electronic music came out of very underground depression-era futuristic art movements and more or less remained there until Delia Derbyshire made it cool in the 1960s. In any case, most of those old speech synthesis machines didn\u2019t use any electric signals at all, so under our modern OED definition we may not consider them synthesizers. Sound synthesis as a scientific discipline I would argue begins with the work of Rudolph Koenig, who in 1862 invented the first primitive oscilloscope (powered by bunsen burner!) - the manometric flame apparatus. With this he did lots of pioneering research in studying what happens when two different tones mix with one another - in other words, he was doing additive synthesis. Again, much of this related to speech synthesis - he used it to find the \u201coptimal\u201d frequencies of vowels, which basically touched on what we now know as formants. But some of his work related to music as well - he invented lots of complex tuning devices which were intended to be capable of tuning any musical instrument, including producing frequencies that extended beyond human hearing range. In 1865 he combined his research on vowel tones and with a design by Hermann von Helmholtz and created a speech synthesis machine simply called\u2026 \u201cthe sound synthesizer.\u201d It looked like this:  Those round things are Helmholtz resonators, and are tuning forks (which play the musical tones) hooked up to adjustable metal cylinders which emulate the resonant frequencies of the vowels within a cavity. The thing ran on electromagnets, but it wasn\u2019t an electronic musical instrument. Essentially, you can recreate a similar effect to this on a modern electronic synthesizer by playing a simple tone hooked up to a filter with the resonance cranked up and adjusting the cutoff frequency to match that of a vowel tone formant. There are far better and more accurate ways of synthesizing vowel sounds nowadays, but it still kind of works. While I was at uni I made a sampler instrument from a schwa tone and managed to roughly hit every vowel sound on the IPA chart by playing with filter resonance, with varying fidelity. Still, some might still argue that machine is not a synthesizer, since it was just an organic sound being played into a cavity and amplified (albeit also manipulated a bit), but that\u2019s really not that far off from how an acoustic guitar works. So our next possible candidate comes from the telecommunications revolution, Elisha Gray\u2019s harmonic telegraph, from 1875:  Starting to look kind of familiar now, right? What this is, in modern synthesis terms, is 25 oscillators hooked up to 25 keys, each playing a fixed tone. That\u2019s it. It was used to play melodies down the phone. Know those three beeps you hear when you dial a wrong number? That starts here. However, it doesn\u2019t really fit the OED definition of a synthesizer because it cannot, by any reasonable definition, generate a wide variety of sounds, least of all by generating and combining signals of different frequencies. It was only capable of generating one tone at 25 fixed pitches, and did so using 25 circuits, one for each key. You couldn\u2019t modulate anything. So our next stop on this journey, which I think is the one which would get the most votes for \u201cfirst sound synthesizer\u201d if you polled a sample of music tech buffs, is the Telharmonium:  That was the comparatively compact first version, built in 1896. The second version was colossal and majestic, like early voltage controlled synthesizers, and needed a whole room. As you might infer by the presence of sheet music in the above picture, this one was actually designed as a musical instrument. Not just that, it was designed to be able to imitate a wide range of orchestral instruments. It works the same way as the ultimately successful Hammond Organ, which was modelled on it, by creating sounds through stacking tones on top of one another which were selected using tonewheels - this is undeniably additive synthesis, and it was capable of creating a wide range of tones and playing many at once. The tones were transmitted through electrical wires, and the resulting sound was played through a telephone receiver reverberating around a huge cone - one of the first loudspeakers. It could also be transmitted down the telephone using the existing technology, like the harmonic telegram, and people could dial a number and tune into performances. Obviously it wound up being considered impractical, not only because it was huge and sent electricity bills skyrocketing as vacuum tubes hadn\u2019t even been invented yet, but also because broadcasting music performances by telephone ended up annoying loads of people who would get caught up in crosstalk and hear weird futuristic music, whose mere existence was already controversial enough. If you want to learn more about how the Teleharmonium worked I recommend checking out the diagrams on the original patent: US580035A. There are still some very pedantic people who might argue that the Telharmonium and the Hammond Organ aren\u2019t synthesizers, because they\u2019re not pure electronic musical instruments, but electromechanic ones, thus placing them in the same category as electric guitars. Such people would probably consider the first synthesizer to be the Theremin, invented in 1919 by Leon Theremin.  This is a diagram of the modules in a Theremin:  It uses a couple of signal inputs to control pitch and volume and has an adjustable filter. It\u2019s all electronic. So that\u2019s definitely a synthesizer, and that\u2019s as far as we go. ",
            "date": "Answered November 21, 2016",
            "views": "25",
            "upvotes": " View 9 Upvoters ",
            "upvoters": [
                {
                    "user_id": "James O'Connor",
                    "user_href": "/profile/James-OConnor-8"
                },
                {
                    "user_id": "Pramodya Thilakarathna",
                    "user_href": "/profile/Pramodya-Thilakarathna"
                },
                {
                    "user_id": "Noah Final",
                    "user_href": "/profile/Noah-Final"
                },
                {
                    "user_id": "Syrinx",
                    "user_href": "/profile/Syrinx-3"
                },
                {
                    "user_id": "Brandon Perryman",
                    "user_href": "/profile/Brandon-Perryman-5"
                },
                {
                    "user_id": "Tomas Urban",
                    "user_href": "/profile/Tomas-Urban-1"
                },
                {
                    "user_id": "Tom Robinson",
                    "user_href": "/profile/Tom-Robinson-110"
                },
                {
                    "user_id": "Eric Becker",
                    "user_href": "/profile/Eric-Becker-9"
                },
                {
                    "user_id": "Brad Bjorndahl",
                    "user_href": "/profile/Brad-Bjorndahl"
                }
            ]
        }
    ]
}