{
    "title": "Which 3D render software do you use? - Quora",
    "tags": [
        "Rendering (computer graphics)",
        "3D Technology"
    ],
    "response": [
        {
            "author_info": {
                "name": "Ayden Ye",
                "href": "/profile/Ayden-Ye"
            },
            "answer_text": "My team uses Blender to render our 3D VR Videos. Check it out! The highest form of immersive media gives its viewers the feeling that they are viewing the scenes in person and directly with their own eyes. We perceive the real worlds around us with two eyes that are 2~3 inches apart. Whatever object we look at, its image gets projected on our left and right eye retinas at slightly different positions, and such binocular disparity helps us perceive the scale and the depth; the larger the disparity is, the closer we feel the object is to us (depth). For a certain perceived size, the further away the object is from us, the larger we know it actually is (scale). When we watch contents in VR mode, VR goggles or VR headsets use two separate input channels for each of our eyes and thus \u2018immerse\u2019 us into the scene. If the content is in 2D, the system automatically generates two scenes onto two display screens so that the left display presents a fraction of the scene slightly more on the right than the right display does.  the left display presents a fraction of the scene slightly more on the left than the right display In contrast, 3D is produced by using 2 cameras offsetted from each other to capture materials with different binocular disparity for each eye and can thus give viewers a much more real sense of depth and scale. So this Blender tutorial will walk you through how you can use a pair of virtual cameras to render a piece of 3D VR content with Blender.  Blender project: Thanksgiving Parade | 360 Video by Tate Assuming you\u2019ve got your 3D scene ready, here is a brief summary of the workflow we\u2019d adopted: 1. Configuring the render engine Change the render engine to \u2018Cycles Render.\u2019Set the output format.2. Set the stereo 3D display mode 3. Configure the camera Change the camera type to a 360-degree oneMake your camera a stereo pairSet the interocular distanceConsider where the convergence plane should beSet the convergence plane distance and finalize the position of the stereo pairs4. Render the scene out and upload onto VeeR! Blender project: Lowpoly Japanese Garden 360 in 4k by Dominik Kozuch Step 1: Configure the render engine First, set the render engine from \u2018Blender Render\u2019 to \u2018Cycles Render\u2019: for various reasons this new engine is much more powerful in rendering photorealistic 3D scenes than the classic one. Go to \u2018render layers\u2019 on the properties panel, check \u2018views,\u2019 select \u2018Stereo 3D,\u2019 and then check both left and right.  Then click on the camera icon and go to \u2018output.\u2019 Choose a destination folder. If your final product is a still 3D image, select an image format. If you are making an animation, you can export it in a video format or export individual frames as images. The first option is easier but also a little bit risky because you\u2019d lose the whole render if some error happens half way. Images require you to do more legwork to bring together the images although it\u2019s safer. Knowing that, under \u2018Views Format,\u2019 select \u2018Stereo 3D.\u2019 Moving on to set the output format \u2013 because our final product would be two renders \u2013 one for each eye, we\u2019ll need to decide on what layout the two renders should be present in. Because we are rendering for VR, we\u2019d choose some format that presents the renders for two eyes in parallel and without overlapping with each other. Thus, you can choose Stereo Mode as either \u2018Top-Bottom\u2019 or \u2018Side-by-Side.\u2019 Platforms like VeeR recognizes the top/left render as the left eye input channel and the bottom/right render as the right eye input channel.  Step 2: Set the stereo 3D display mode However, you don\u2019t usually use a VR headset to preview the scene when you are creating it, and so you can click on \u2018Window\u2019 > \u2018Stereo 3D,\u2019 and select \u2018Anaglyph\u2019 to preview your work. An anaglyph 3D video contains two differently filtered colored videos (overlapping with each other), one for each eye, and you can watch it by wearing a pair of red-cyan glasses so each of your eyes only sees a single image, like you do when watching a 3D movie in the cinema.  Step 3: Configure the camera Change your camera type to \u2018panorama,\u2019 and then \u2018equirectangular,\u2019 as described in this blog. This allows you to have your render results in 360-degree. Then, select your camera, go to \u2018data\u2019 in the property panel, and go down the \u2018Stereoscopy.\u2019 Select \u2018Off-Axis\u2019 under Stereoscopy: this is the ideal format since it is the one closest to how the human vision works.  Then we\u2019ll need to set the \u2018Interocular Distance\u2019 and the \u2018Convergence Plane Distance.\u2019 You can set interocular distance based on how big you want your 3D objects to be perceived. Click on one of your objects, press \u2018N\u2019 to check its dimensions. Calculate the ratio between the scale that object has in reality over the model\u2019s scale. The interocular distance you set for your stereo pairs should be that ratio times a normal human pupillary distance. It\u2019s safe to use Blender\u2019s default interocular distance value 6.291 as a normal human pupillary distance. In Blender, the convergence plane is the grey plane you can see in the 3D viewport after changing the camera to a stereo pair. It\u2019s where the two cameras converge. Visual discomfort or brain fatigue may easily occur when viewers stare at some virtual object that is too far from the convergence plane you set, and a larger distance between the object and the plane the viewers can withstand is associated with smaller interocular distance and larger convergence plane distance. And thus, Blender recommends that you set your convergence plane distance at least 30 times the interocular distance. So far we\u2019ve got all the parameters covered but haven\u2019t yet decided where exactly we want the camera to be: it\u2019s still at the default position. To position the camera properly, we\u2019d first consider where we want the convergence plane to be. There\u2019s no standard answer, so just keep two facts in mind: There is only a limited zone around the convergence plane where viewers can look at objects comfortably.As illustrated by the image below, virtual objects that are closer to the camera than the plane is would have a pop-out effect(right), while objects that are behind the plane would be perceived as \u2018deep into\u2019 the screen(left). Therefore, consider what your main characters/objects are, or, say, where your main story happens, and drag your camera to move the convergence plane to that place (the plane moves with the camera given a fixed convergence plane distance). To avoid visual discomfort for viewers, keep in mind: a) where important characters are the densest/where users would focus on for the longest period of time, and b) what objects you would like to apply a pop-out effect on and what objects you would like a \u201cdeep into\u201d effect. After you reached your perfect position for the convergence plane through moving the camera, press \u20180\u2019 on the Numpad to view from the camera\u2019s perspective. If it doesn\u2019t capture all you want, you can make the convergence plane larger and drag the camera pair further away from the scene to keep the convergence plane at the same position as before. Step 4: Render the scene out and upload onto VeeR So far we\u2019ve got all the configurations done. It\u2019s recommended that you render a piece of low-resolution test to check if the final product is what you want. After you\u2019ve got your final 3D VR work rendered out, remember to upload it on to VeeR. Just select 3D top-bottom or 3D side-by-side when uploading and VeeR would handle everything else to have your work ready to be viewed in VR mode. We are looking forward to enjoying your 3D VR content with millions of users on the platform!  For more about Blender, also check out Why Blender Is The 3D Animation Software You Need For Your VR Projects. If you are a 360 VR creator, feel free to follow and request me any 360 or/and VR relevant questions! :) ",
            "date": "Answered September 27, 2018",
            "views": "267",
            "upvotes": " Answer requested by Shihab Naeem"
        },
        {
            "author_info": {
                "name": "Chris Lockwood",
                "href": "/profile/Chris-Lockwood-4"
            },
            "answer_text": "I\u2019m currently using Cinema 4D with Redshift. I\u2019ve been doing 3D since about 1990. I started off with Alias Sketch!, which was a pretty primitive 3D application, and quickly found it was almost unusable for my needs, although it did seem to have a decent renderer. I also experimented with other programs like Bryce, Infini-D, Terragen, Lightwave 3D until, after a lot of research, I moved onto using form-Z for modeling and Electric Image for rendering and animation, a combination I stuck with for around 20 years. Eventually, Electric Image stopped being developed, and even though it is still being sold, it is mostly used by hobbyists or users who have used it as long as I have, but I just found that it could not keep up with what I needed it to do. About six years ago I decided to change to a more robust 3D software. I was looking at 3D Studio MAX, Maya and Cinema 4D. I eventually chose C4D because at that time I was working at a graphic design firm with 15 staff members, and we used Macs exclusively, and even though I was the only one doing 3D work, I could easily set up a rendering network using my co-workers\u2019 computers after hours. More recently I switched jobs and went to work for a 3D firm that used 3D Studio Max exclusively. It had a lot of similarities to Cinema 4D, but it was PC only. About two years ago I decided to go back to quit that job and return to freelancing, so I had to make a decision which 3D software to use. I could either continue using 3DS MAX or go back to C4D. Most of my work is related to the petroleum industry. The obvious choice for that kind of work is 3DS Max only because my clients provide CAD files in a lot of formats 3DS can import. But I hated 3DS for a lot of reasons. The first was the fact that it could only have a single scene open at any time, it was really outdated and unstable compared to Cinema 4D, and it had very little support for Adobe Creative Cloud applications. So I went back to Cinema 4D. A very basic version of Cinema 4D actually comes with Adobe After Effects. And After Effects can share cameras and lights with C4D. C4D also outputs files directly to layered Photoshop files, making it really useful in the kind of work I do. When I decided to go back to C4D, I set out to build the best computer I could afford to work with it. I was looking at specs on systems from companies like Boxx, Main Gear, Titan, and Digital Storm. To get the specs I was looking for would cost me about $8,000 to $11,000. But a friend of mine told me we could probably build a system with the same specs for about half the cost. He was right. We ended up with a PC that has a 3.0GHz 6-core processor, 128 GB of RAM, 1600-watt power supply, single GTX 1080ti GPU (with room for up to three more), 2 TB M.2 SSD and 2 TB SATA hard drive, motherboard and eATX enclosure, all for less than $5,000. I added two 4K LG monitors and an 8TB NAS RAID for about $1400 more. When choosing your software, it\u2019s important to know what kind of 3D work you want to do. For motion graphics and the kind of industrial animation I do, C4D provided the best toolset. But I also needed speedy rendering which meant either using expensive internet rendering farms or a GPU based rendering engine. I opted for a GPU-based rendering engine, which at the time was Octane. So I built my system around that. Since then Redshift also came onto the market and that is my rendering engine of choice. My biggest hurdle was getting files from clients. Most of them use CAD applications like Pro-E/CREO, SolidWorks or AutoCAD. I would get native files or exported files in DWG, STEP, IGES, 3DS, or STL formats, none of which Cinema 4D could open. To solve that I bought Polytrans which handles a lot of native CAD formats as well as all the export formats I need. ",
            "date": "Answered September 23, 2018",
            "views": "200",
            "upvotes": " Answer requested by Shihab Naeem"
        }
    ]
}