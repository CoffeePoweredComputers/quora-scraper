{
    "title": "How does the digital camera instantaneously translate light into pixels on the screen? - Quora",
    "tags": [
        "Pixels",
        "Computer Vision",
        "Image Processing",
        "Digital Cameras",
        "Digital Photography",
        "Visible Light",
        "Cameras",
        "Photography",
        "Electronics"
    ],
    "response": [
        {
            "author_info": {
                "name": "Terry Mercer",
                "href": "/profile/Terry-Mercer-17"
            },
            "answer_text": "**Thank technology. ** First, the pixels must be exposed\u2026 Much like the x-ray machine, except it uses just regular light rather than radiation. The pixels are \u2018in the sensor\u2019 and they are photo sensitive, and their location and \u2018response\u2019 are assigned numbers. Much like the thermal transfer receipt you get at some stores\u2026 when you leave them in the sun light they turn light grey to full on black. Photo sensors are made up of tiny RGB (red, green, blue) pixels\u2026 which are light sensitive. The more like they are exposed to, the darker that section becomes, and that intensity or shade of darkness is assigned a number. The two most common light detecting sensors (in cameras) are either a **charge-coupled device (CCD)** or a **CMOS image sensor. **Some of the most expensive cameras have THREE SENSORS (usually CCD) - one for \u2018R\u2019 - one for \u2018G\u2019, and one for \u2018B\u2019, but those are mostly digital video cameras. When the shutter button is pushed, the \u2018aperture\u2019 (leafs inside the lens, usually) opens up, allowing light through from a given period of time (\u2018shutter speed\u2019); which is two thirds of the \u2018exposure triangle\u2019 (ISO or \u2018sensitivity to light\u2019 is the third factor, and on your better cameras that sensitivity has greater adjustment capability, to capture images in lower light... or at faster shutter speeds, which ultimately means less time for the light to hit the sensor). The little computer inside a digital camera, electronically switches all these colored pixels on and off very quickly, based on the \u2018number\u2019 (intensity, and color) of light that was \u2018captured.\u2019 Now, that gets the pixels \u2018exposed\u2019 - BUT does NOT get you an image. For that, you need FOCUS, and either a lens, or pinhole opening (comparable to the length of exposure and amount of light). Then saved (to memory built into the camera or removable) Then \u2018read\u2019 and \u2018translated\u2019 by the tiny computer in the camera designed to \u2018interpret\u2019 the data that was saved from the sensor. Imagine looking out of a window at something\u2026 being able to FREEZE that image on to the glass, then having it break into 20 million little uniform pieces\u2026 that were sequentially numbered, with the exact color, shade, intensity, and focus saved onto that tiny piece of glass. That is sort of what a photo sensor does, really fast, digitally, with the ability to nearly instantly \u2018reassemble\u2019 the pieces 99.999999% of the time without problem. Most cameras \u2018compress\u2019 and \u2018average\u2019 (colors, shades, and intensities). That is basically what JPG images are, compressed images. Rather than 16.7 million shades of a color (for exactitude), the computer picks the closest match to that color out of 65,536 options, which is close enough for the average human eye\u2026 and a significant savings of space (to store the data) and time (to reassemble and transmit the data). The better the camera\u2026 the more pixels there are, allowing for both larger sizes and more color options, or faster capturing and saving of the pixel information. It\u2019s science, on steroids. The \u2018reassembly\u2019 of the pixels is then transmitted to \u2018the screen\u2019 (much like a Television). Viola\u2019 you can see the \u2018window\u2019 re-assembled. ",
            "date": "Answered September 16, 2019",
            "views": "129",
            "upvotes": " View Sharers"
        }
    ]
}