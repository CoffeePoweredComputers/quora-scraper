{
    "title": "What are the limitations of AI? - Quora",
    "tags": [
        "Limitations",
        "Artificial General Intelligence"
    ],
    "response": [
        {
            "author_info": {
                "name": "Tony Reno",
                "href": "/profile/Tony-Reno-1"
            },
            "answer_text": "There are no limits. People fail to recognize that natural human intelligence is not magical or mystical. It is just the end result of atoms interacting in physical ways that are all well understood. It is not yet well understood how those physical interactions create the emergent properties of consciousness and mind/body interactions. But it is well understood that they do so. The scale is pretty clear too. There are approximately 90 billion nerve cells in the human brain, only 16 billion of which are in the cerebrum where most of planning lies. And even the general ideas behind it all are fairly clear. Consciousness appears to arise out of an interplay between the brain stem, which connects directly to the body parts, and primary sensory and motor areas of the Cortical homunculus. The basic idea is that the brain can somehow simulate experiences that are similar in kind to actual experiences and this forms the basis of conscious thought. There is still 2 real mysteries as to how the sense of qualia (our internal subjective world) comes about, and how the conscious thoughts then create physical responses. But while these are mysteries, the scale of the mystery is understood. It cannot be more than the interplay of 4 quadrillion bytes (4 peta-bytes) of information as that is the extent of what the dendrites of brain cells are capable of encoding. It also can't require more than 3 billion sensory inputs as that is the highest extent of what the combination of the optic nerve and the spinal cord can encode. Finally, human encoding occurs at no greater than 400 hertz, or 400 cycles per second. There are not many relevant mysteries in either the processing mechanics or the sensory input mechanics of the human intelligence apparatus. It is the overarching software that is mysterious. However, as mysterious as it is, it is remarkably robust, so it can't be too fragile or too exacting. It has to have broad working tolerances. The only AI problem now is that we aren't yet at the 3 billion bit sensory input level with a 2 exa-byte processing capacity that the brain operates at. That being said, even at the level we are at, we have already shown that the speed and accuracy of artificial intelligence achieves what appear to be qualitative leaps with every 2 orders of magnitude (100-fold) levels of speed and capacity improvements. Photo, then video processing capacities indicate that these are rapid and ongoing improvements. The holy grail for AI, though, is not human computation capacity. In many ways that's probably already exceeded. The holy grail for AI is in sensory and motor capacity and in human efficiency. Sure Watson's banks of machines and Google's deep databases can surpass the exabyte upper limits of human capacity, but humans do this in a mobile frames that runs on 100 watts of power. That's why we aren't yet impressed by AI's achievements. They simply lack the efficiency and mobility to match humans. Still, that is no more than 20 years away. And the big \"gotcha\" that people have not internalized is that people are far from the most efficient possible. People are inefficient by at least a factor of 10, and probably a factor of 10,000 from what is possible. Once people are cheaply surpassed for general purpose capacity, all capacities, this level of advance will speed up dramatically. This breakthrough point (a general purpose, inexpensive machine surpassing human ability in every way, from chess to basketball, brain surgery to mining, R&D to counseling and parenting) is called the singularity because it is impossible to compare the times before to the after. The only things limiting what is impossible are the physical limits of chemistry. Complex chemicals can't set up shop on stars, for instance. Beyond those limits, there is plenty of abundance on the earth and solar system for a phenomenal future.  Of course ethics matters. Somehow ethics has arisen from evolutionary natural intelligence such that parents don't eat their children when they are young and weak, and children don't eat their parents when they are old and weak. We will need to do everything in our power to ensure that these ethics cross the AI barrier.  ",
            "date": "Answered April 24, 2016",
            "views": "25",
            "upvotes": " View 9 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Robert Scronic",
                    "user_href": "/profile/Robert-Scronic"
                },
                {
                    "user_id": "Rutvay Dhami",
                    "user_href": "/profile/Rutvay-Dhami"
                },
                {
                    "user_id": "Larry Behrens",
                    "user_href": "/profile/Larry-Behrens-1"
                },
                {
                    "user_id": "Ali Hikmat",
                    "user_href": "/profile/Ali-Hikmat"
                },
                {
                    "user_id": "Joel V Benjamin",
                    "user_href": "/profile/Joel-V-Benjamin"
                },
                {
                    "user_id": "Chandoo",
                    "user_href": "/profile/Chandoo-6"
                },
                {
                    "user_id": "Jeff Holliday",
                    "user_href": "/profile/Jeff-Holliday-1"
                },
                {
                    "user_id": "Rachit Srivastava",
                    "user_href": "/profile/Rachit-Srivastava-3"
                },
                {
                    "user_id": "Rob Casey",
                    "user_href": "/profile/Rob-Casey-5"
                }
            ]
        },
        {
            "author_info": {
                "name": "James Earl Adams III",
                "href": "/profile/James-Earl-Adams-III"
            },
            "answer_text": "I will assume the question pertains to \"the ultimate limits of A.I\" rather than the present ones. Intelligence is partly a function of computation (as well as design), so the capabilities of an A.I. will correlate positively with increases in the computation available to it. The limits of A.I. are very dependent on the alternative question, \"What are the limits of computation?\" There is no conclusive answer here, but there are high and low estimates to guess between.   Low If you're especially pessimistic, you'll suppose that consumer electronics stop seeing gains in the early 2020s. Around that time, Moore's law would be pronounced dead and subsequent generations will come to the realization that quantum computing is unfeasible and will never materialize.  Given this scenario, you will still have autonomous cars and drones and real time translators. If sufficient knowledge of the brain is ultimately achieved, whole brain emulation will still be technologically feasible, so even in this grim scenario, the limits of AI will at least be Turing capable chatbots and the preservation of copies of loved ones. High A paper from MIT did the back of a napkin calculation to guess at the ultimate limits of computation allowed by physics. If you could arrange an amount of matter so that it is in the best possible form of computing device for that amount of matter, what could it do? That's the question posited and answered by the paper.  The conclusion reached is that a kilogram of such matter could perform in a second what the combination of all human brains that have ever lived could produce in that same second -- except 100 thousand billion billion times over. That's a nonsensical estimate, because it makes no consideration of energy, the speed of light, error correction or the economics that could ever drive the creation of such material. It does, however, demonstrate just how high the ceiling stands.  Extremes in either direction normally make poor predictions, so I will suppose that the true limits of AI are someone between these.  Perhaps AIs will be better than human brains by ONLY a factor of 10^10 rather than 10^23.  ",
            "date": "Answered March 30, 2016",
            "views": "22",
            "upvotes": " View 1 Upvoter ",
            "upvoters": [
                {
                    "user_id": "Peter Melville",
                    "user_href": "/profile/Peter-Melville-2"
                }
            ]
        }
    ]
}