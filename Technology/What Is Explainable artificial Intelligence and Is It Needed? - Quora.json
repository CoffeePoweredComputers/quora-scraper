{
    "title": "What Is Explainable artificial Intelligence and Is It Needed? - Quora",
    "tags": [
        "Learning Outcomes",
        "Deep Learning",
        "Artificial General Intelligence",
        "Intelligence",
        "Artificial Intelligence",
        "Machine Learning",
        "Computer Science",
        "Science",
        "Technology"
    ],
    "response": [
        {
            "author_info": {
                "name": "Darryn Reid",
                "href": "/profile/Darryn-Reid"
            },
            "answer_text": "It's about the ability for the machine to explain the reasoning behind its actions to a human, and it takes both the form of being able to explain in formal language to a computer scientist and of being able to explain to the user of the system. It's very important because it pertains directly to the confidence that the human will have in using the system, and, more formally, whether that trust is well placed by being able to prove things about the behaviour of the machine. This is particularly important in applications where the consequences of error can be grave. I have described this as the \u201cassurance problem for autonomy\" to distinguish it from traditional verification. One of the difficulties sith deep networks is that explanation in terms of the reasoning behind a decision is very difficult, because there really is no reasoning, just computation of a function. Early efforts at assurance using verification could only do so much, because, after all, the point of AI is to be able to work in environments involving at least some level of deep unpredictability. My work has centred on establishing hidden empirical symmetry conditions characterising the environment, corresponding formal objects known as invariant conditions or axioms, and then using these as the basis for reliable reasoning within known limits, which is how I define the assurance problem in my work. The other thing that might interest you is that I've also proposed that machine AI needs not to primarily explain itself to other agents (including humans), but first and foremost needs to be able to explain its behaviour to itself, as the central characteristic of meta-reasoning and meta-learning, which is, I believe, a crucial enabler for why humans can deal so effectively with varying degrees of uncertainty. ",
            "date": "Answered April 25, 2019",
            "views": "54",
            "upvotes": " Answer requested by Aaron Anthony",
            "upvoters": [
                {
                    "user_id": "Genny Harrison",
                    "user_href": "/profile/Genny-Harrison"
                }
            ]
        },
        {
            "author_info": {
                "name": "Hakan Nordahl",
                "href": "/profile/Hakan-Nordahl"
            },
            "answer_text": "A little unusual formulation which where AI is both needed and explainable? You got me thinking and I think the answer on your question is the need to extend the effective action window. Example: blood pressure medication and many other drugs has been shown to increase for early dementia and even death. Wouldn\u2019t it be nice to be able to consider effective actions before you walk into the fog and while your brain is still working? Changing your diet you don\u2019t easily do over night e.g. remove sugar and reduce bread from your diet load your diet with olive and coconut oil. Such informed decisions takes years to cultivate. An essential mechanism that need improvement in AI is a semantic feedback mechanism. I have proposed a generic way to do that in my other contributions to both Quora and LinkedIn discussions. ",
            "date": "Answered April 24, 2019",
            "views": "90",
            "upvotes": " View 1 Upvoter "
        }
    ]
}