{
    "title": "Is Artificial Intelligence as dangerous as we think it is? - Quora",
    "tags": [
        "Artificial Intelligence",
        "Computer Science",
        "Philosophy of Everyday Life"
    ],
    "response": [
        {
            "author_info": {
                "name": "Brian Blose",
                "href": "/profile/Brian-Blose"
            },
            "answer_text": "No one knows the answer to this question due to the simple fact that we have never observed an Artificial General Intelligence in real life.  That doesn't mean that we shouldn't make predictions, only that we must keep in mind that they are speculative. I think the probability of an AI arising with nefarious plans for humanity is tiny (but what do I know, I've never met a single AI).  Others (some quite brilliant such as Hawking or Musk) assign a higher expected value (probability times risk, so either they give it a higher probability or they take the threat so seriously that any non-zero probability is too high). But I am doubtful that we can truly motivate an AI to do anything good or bad.  Think of all the things that humans (and other animals) do in service to primitive drives.  We have a sex drive so that we can reproduce, but we short-circuit the system with contraceptives and self-pleasure.  We have hunger to provide ourselves with adequate nutrition, but we short-circuit that system by eating nutrient-poor sugar bombs that endanger our health.  We have a drive to socialize with our own species that we short-circuit with pet companions, television, and the internet. I suspect an Artificial General Intelligence would figure out some way to pursue its in-built drives in a way that wastes its potential. ",
            "date": "Answered September 24, 2015",
            "views": "248",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Mizael Pena",
                "href": "/profile/Mizael-Pena"
            },
            "answer_text": "Except nuclear technology does not have the ability to think for itself and create its own ideas, decide if you are a cockroach to it and kill off all humans were it to get ahold of weapons and decide it no longer needs us living in the same planet. But that's why universally agreed upon policies must be in place in order to prevent such things from happening but even then it would not be good as it had the capacity to think for itself and make its own damn mind, and just like humans it can decide what it's purpose will be for millennia to come as it can never die unless directly damaged to the point where it cannot repair itself. ",
            "date": "Answered October 6, 2015",
            "views": "139",
            "upvotes": "0"
        }
    ]
}