{
    "title": "Why are old people so bad at technology? - Quora",
    "tags": [],
    "response": [
        {
            "author_info": {
                "name": "Thomas L. Johnson",
                "href": "/profile/Thomas-L-Johnson-1"
            },
            "answer_text": "Because at a certain point, learning the newest technology is simply governed by the Law of Diminishing Returns. My 33 year old niece, who has a master\u2019s degree and works in public schools had a student teacher working with her last semester and she marveled at how advanced that student teacher was at things like Google Docs and advanced applications on Excel. For once, it was nice to see a Millennial admitting that once you get out of college a few years, your computer skills tend to remain on the plateau they were on when you studied unless you are in the industry itself. When I was in my 20s & 30s, I was an expert on applications like LOTUS 1\u20132\u20133, dBase 3Plus, WordPerfect, and numerous other PC and Macintosh software packages (all of which have disappeared or been superseded). I could program in FORTRAN or COBOL and create complicated statistical studies. I used to teach classes for career programmers who had been left behind by the PC Revolution. They thought I was some sort of guru. At 70, I am hardly a guru; I don\u2019t need to be. But I spend a lot of time on computers and feel comfortable creating a course of Moodle or a spreadsheet on Excel. I haven\u2019t programmed in decades and likely never will again. I used Google Docs to write a book with German colleague and can Photoshop well enough the clean up my pictures and have even had a few that ended up in print. At a certain point, most of us realize that we only need to know so much to remain at a level of comfort and that benefits have to exceed costs. The need to be regarded as something of a guru is best left to those who are 50 years younger. I once said that if I had used a fraction of the time I have spent learning technologies and applications that I no longer use studying French, I would be fluent. That would be the idea behind the Law of Diminishing Returns. ",
            "date": "Answered April 8, 2018",
            "views": "115",
            "upvotes": " View 128 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Julie Gates",
                    "user_href": "/profile/Julie-Gates-5"
                },
                {
                    "user_id": "James Denby",
                    "user_href": "/profile/James-Denby-1"
                },
                {
                    "user_id": "Alice Folk",
                    "user_href": "/profile/Alice-Folk"
                },
                {
                    "user_id": "Ashley Goldbaum",
                    "user_href": "/profile/Ashley-Goldbaum"
                },
                {
                    "user_id": "Alan Armstrong",
                    "user_href": "/profile/Alan-Armstrong-21"
                },
                {
                    "user_id": "Susan Vaughan",
                    "user_href": "/profile/Susan-Vaughan-10"
                },
                {
                    "user_id": "Tom Jones",
                    "user_href": "/profile/Tom-Jones-1375"
                },
                {
                    "user_id": "Sandy Meadows",
                    "user_href": "/profile/Sandy-Meadows-2"
                },
                {
                    "user_id": "Leah Jaded",
                    "user_href": "/profile/Leah-Jaded"
                },
                {
                    "user_id": "Robert Berger",
                    "user_href": "/profile/Robert-Berger-28"
                }
            ]
        },
        {
            "author_info": {
                "name": "Jim Seidman",
                "href": "/profile/Jim-Seidman"
            },
            "answer_text": "Each generation of devices or applications draws on a set of conventions and metaphors to make it more understandable. The last pre-Windows round of PC applications introduced buttons made out of text labels surrounded by borders. Then Windows used 3D-looking buttons to extend the metaphor that you were \u201cpushing\u201d the buttons to do things. By now, UI standards such as Material Design call for flat buttons, assuming that people know what to do with them. If you continuously use something as it evolves, it\u2019s easy to keep up. But if you miss a couple of generations of technology, catching up is hard for everyone. Everything is like that. I\u2019ve seen even Digital Natives struggle when switching between platforms that do things modestly differently, such as iOS and Android. You may think one of those platforms is much more intuitive than the other, but that\u2019s largely due to familiarity. I\u2019ve been using computers for 40 years now, and can write code in several languages. Yet I still get repeatedly flummoxed by the redesigned version of Snapchat, because it doesn\u2019t follow the UI metaphors that I\u2019m used to. If Snapchat\u2019s interface was inspired by existing metaphors, they\u2019re from apps that I never used. When you grow up with something, you learn it more slowly, but then it seems \u201cnormal.\u201d But many elderly people have gone through their careers without needing to make heavy use of high tech. Sure, they could go to classes to learn this stuff, but to what end? Is it worth spending a bunch of time learning Facebook instead of hanging out with friends and family? Unless someone has a project in mind, there\u2019s no reason to learn about relational databases. And smartphones are actually pretty frustrating to use for anyone with even modestly impaired vision, as is common with many older people. Also, for many of us, our school or work provides much of the motivation to learn technology. If your job requires you to use Excel, of course you\u2019re going to learn Excel. A lot of the navigation and formatting metaphors will in turn make other programs easier to use. People who have retired don\u2019t have the same motivations. Which brings us back to my opening point: not spending dozens of hours a week using technology for work will in turn make it harder to figure out other technology for personal use. ",
            "date": "Updated April 12, 2018",
            "views": "26",
            "upvotes": " View 5 Upvoters",
            "upvoters": [
                {
                    "user_id": "Elizabeth Downs",
                    "user_href": "/profile/Elizabeth-Downs-7"
                },
                {
                    "user_id": "Heather Jedrus",
                    "user_href": "/profile/Heather-Jedrus"
                },
                {
                    "user_id": "Praveen Sharma",
                    "user_href": "/profile/Praveen-Sharma-14"
                },
                {
                    "user_id": "Harrison Boyle",
                    "user_href": "/profile/Harrison-Boyle"
                },
                {
                    "user_id": "Jonathan Cheng",
                    "user_href": "/profile/Jonathan-Cheng-17"
                }
            ]
        }
    ]
}