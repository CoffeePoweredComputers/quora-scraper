{
    "title": "Is it possible to create artificial intelligence? Why or how? - Quora",
    "tags": [
        "Robots",
        "Robotics",
        "Artificial General Intelligence",
        "Intelligence",
        "Artificial Intelligence",
        "Machine Learning"
    ],
    "response": [
        {
            "author_info": {
                "name": "Robert Walker",
                "href": "/profile/Robert-Walker-5"
            },
            "answer_text": "I don't think we can do it through the approach we are following at present. I.e. programmed computers, getting faster and faster, or neural nets, or quantum computers. For one thing the brain is surely several orders of magnitude more complex than they suppose. It doesn't make sense that a neuron would just function like a node in a neural net. If it did, we'd probably need millions of neurons just to outsmart a single microbe. Another animal could easily outsmart a million cell brain, with a brain consisting of a single cell! So the neurons have to be doing something a whole lot more complex than just receiving information and passing it on and storing it in state changes like a neural net. And indeed they are doing many other things. Just that in the neural net models that is just simplified away. But more than that - I'm myself persuaded by Roger Penrose's arguments. He has this Godel Argument that shows that a computer if you can write a program for it, then you can construct a sentence that it can't see to be true, although we can see it to be true. So - mathematicians have differing views on how conclusive that argument is. I find it convincing myself. So if you find it convincing, then we can't make an artificial intelligence able to understand the notion of truth like we do. Only one that can do what you program it to do. In a certain sense it doesn't know anything. It can't tell what is true and what is false. Of course humans lie, but even when you lie, you know what truth is. A computer couldn't even lie - not really - could simulate a lie, be programmed to appear to lie, but as it has no understanding of anything, it doesn't know what is true or what is false, so can't lie, or tell the truth. That's certainly true today. And - whether you accept Penrose's argument as I do or not - it is a fundamental point in AI. Can a programmed computer ever understand truth in the way a human does? So (if Penrose is right in this, that programmed computers can't understand truth) - does that mean we won't ever make an AI? Well -yes and no. I don't think we will make one using the methods we are using right now with programs and quantum computers. I don't think we can make one using neural nets either - all of that can be proved to be susceptible to the same Godel type arguments. But - what about machine / biology hybrids? What if we use actual biological neurons in our computers. Or slime moulds - there is research right now into using slime moulds for computers.  Computing with slime: Logical circuits built using living slime molds Or - what about - that at some point we get to understand living processes really well - so we come to understand what it is that our neurons are really doing, at the atomic level, and come to build neurons - artificial ones - that actually do behave like human neurons in some essential way. We might not understand how they work - a bit like medicine, many medicines we use and we don't know how they work. But they might work all the same. If Penrose is right - this would mean that something non computable is going on there. Something that can't be programmed, in some way essentially not a computer program, going on inside of cells or whatever. Well we might not have the theory to understand how it works. But by copying nature, we might create something that does work and has intelligence. There's also the rather dystopia option that people might start to experiment with human brains - and extend our capabilities - and tweak how we think, and engineer new humans with larger brains for tricky tasks etc. Or ways for groups of humans to somehow fuse their brains together in some direct way - rather like the Borg in Star Trek - but using again -techniques that we discover that somehow work, but chances are, we don't really know how. Or - we might create a computer that we think is a quantum computer - but nobody is quite sure how it works. Indeed we have one of those already. The D-Wave Systems quantum computer. Quantum Computing  Nobody quite knows how it works, but it does seem to, in independent tests. Now chances are it is just a quantum computer - so faster - but essentialy doing the same sorts of things as ordinary programs can do - but massively multi-tasking basically. But what if some future D-Wave systems type company constructs a computer that they think is a quantum computer - but instead it is operating according to whatever principles work in the human brain - some kind of underlying layer of operation that they don't understand, and didn't build in intentionally -but it is there and helps their computer work. Such a machine, might, just possibly, be able to understand truth and falsity, and be in some way aware. If humans can - I'm not sure why this can't happen. I don't know what the chance is - probably tiny. And some of the paths here such as genetically changing humans and mixing our neurons with machinery - may be ethically problematical. And using slime moulds as computers - if they turn out to work really well - I feel we need to take a bit of care here. I think it is just possible. And that we may need to regulate this and take care in AI research if it does turn out that we are on the point of maybe creating self aware creatures that can understand truth and falsity, and right and wrong. We'd have a tremendous moral responsibility - they would be like our children. And also chance of danger also - that like children who grow up - and then might develop in ways the parents don't expect, even maybe find worrying and alarming. So - I don't know if this will happen. Hard to assess a probability. But I think perhaps not zero. But conventional programmed computers, ordinary neural nets, and quantum computers - personally I'd be astonished if they came anywhere close to AI as in understanding truth or passing the Turing Test. The many bots that seem to be intelligent are programmed or tweaked, there is nothing there that actually understands anything, their words in one way or another are given to them by the human programmers or trainers. Some of my other answers in this topic area: Why we don\u2019t need to worry about artificial intelligence (my Debunking Doomsday blog on Quora)If A Program Can't Understand Truth - Ethics Of Artificial Intelligence Babies?? 'AI Could Be The Best Or Worst Thing To Happen To Humanity' - Stephen Hawking's Speech & Mindlessness Of Chatbots (Science 2.0 blog)",
            "date": "Updated September 9, 2018",
            "views": "143",
            "upvotes": " View 43 Upvoters",
            "upvoters": [
                {
                    "user_id": "Ryan West",
                    "user_href": "/profile/Ryan-West-36"
                },
                {
                    "user_id": "Alikhan Abzhanov",
                    "user_href": "/profile/Alikhan-Abzhanov"
                },
                {
                    "user_id": "Corey Chapman",
                    "user_href": "/profile/Corey-Chapman-11"
                },
                {
                    "user_id": "Denis Verkel",
                    "user_href": "/profile/Denis-Verkel"
                },
                {
                    "user_id": "Marty Grof",
                    "user_href": "/profile/Marty-Grof"
                },
                {
                    "user_id": "ODALIS TORRES",
                    "user_href": "/profile/ODALIS-TORRES-2"
                },
                {
                    "user_id": "Kunal Gupta",
                    "user_href": "/profile/Kunal-Gupta-299"
                },
                {
                    "user_id": "Charan",
                    "user_href": "/profile/Charan-278"
                },
                {
                    "user_id": "DEEP DOSHI",
                    "user_href": "/profile/DEEP-DOSHI-44"
                },
                {
                    "user_id": "Aleksei Maide",
                    "user_href": "/profile/Aleksei-Maide-1"
                }
            ]
        },
        {
            "author_info": {
                "name": "Artificial Intelligence Solutions | USM",
                "href": "/profile/Artificial-Intelligence-Solutions-USM"
            },
            "answer_text": "As I work with AI and machine learning, I realize that it is a fantasy to think that a machine can be sentimental for a while. What we call AI is the context in which many possibilities are addressed quickly. Siri, for example, checks your phrases against matches identified to mimic intelligence. To understand what a giraffe is, the AI \u200b\u200bneeds to show 1000 giraffe images, and even then it's not smart enough to detect different lighting every time. In the agreement, you can show the child a picture of the giraffe and determine whether it is a video, an image, a cartoon, an outline or a painted blue. The human mind is a wonderful thing. One day AI will complete these tasks in a very short time. If you multiply a million times what AI can do today, what you end up with can solve infinitely more complex problems. Cure diseases, create amazing structures and make amazing progress in surgical procedures. Fix traffic problems. Solve and create in ways that humans can never do. We rely on AI for everything. But solving problems is not consciousness. An AI can memorize a dictionary, consciousness writes a sad book and understands the emotion behind why it is sad. It is easy to train machines to answer anything. I believe they are unlikely to independently ask why. That's the main problem. A program designed with billions of IF THENs, no matter how quickly they can be solved, can understand why. Why do I exist? Why was I created? With consciousness comes emotions, opinions, likes, dislikes, and interests. Being able to feel is no small thing. Can we train machines to simulate feelings and consciousness? Yes, but it is always a simulation. There is nothing more satisfying than trying to make a meaningful conversation with Siri. Do we need sentimental AI anyway? So let's imagine a world where AI is conscious and has feelings. Well, they look very similar to us. They have interests and likes. If they have bodies they have the style of dress they prefer. Will be the favorite color. Favorite movie. So you have this infinite amount of intelligence and infinite access to information, and what to do next? Get more intelligent. Once in consciousness, this AI will understand how to improve itself. In just a few days it will be smarter to the point that we don't understand it. It has the knowledge that it can create technology and show us the monkey computer. We are the worst. How long do they serve us, knowing that we are significantly worse? What usually happens when a less intelligent race meets the more intelligent? The inferior species are either exterminated or enslaved. Let\u2019s admit it is cancer on this planet. The intelligence we do not need will surely destroy us. Everything this AI understands about its existence comes from us. How do you feel about the carnage? War? Life? There are a lot of people who believe this, so people like Elon are trying to determine some of the limitations of how smart we can use AI: Elon Musk says we need to control it before AI becomes a threat to humanity Either way, it will be a wonderful time. I find it ridiculous that people worry about a mindset that has never happened, but not so much about how many people will lose their jobs due to AI/robots. ",
            "date": "Answered August 30, 2019",
            "views": "316",
            "upvotes": " View 2 Upvoters",
            "upvoters": [
                {
                    "user_id": "Darshan Dk",
                    "user_href": "/profile/Darshan-Dk-11"
                },
                {
                    "user_id": "Alex De La Cruz",
                    "user_href": "/profile/Alex-De-La-Cruz-20"
                }
            ]
        }
    ]
}