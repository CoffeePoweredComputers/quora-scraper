{
    "title": "Is there any way to guarantee that a superintelligent AI would not be malevolent? - Quora",
    "tags": [
        "AGI Control Problem",
        "AI Safety",
        "Superintelligence (concept)",
        "Artificial General Intelligence"
    ],
    "response": [
        {
            "author_info": {
                "name": "James P Randolph",
                "href": "/profile/James-P-Randolph"
            },
            "answer_text": "NO! No way to guarantee for multiple reasons!! During the Manufacturing processes in SMT [Surface Mount Technology] some Logic Circuit Components might be damaged via ESD [having a TLA, three letter acronym day] Electrostatic discharge that produces what we call a \u201cwalking wounded\u201d component. That component in the Matrix of a Printed Circuit Assembly and the larger Printed Circuit System will be OK just fine in TEST, and likely in the early stages of its life cycle. But,, it can break down over time and become dyslexic, or intermittent, or error out in a multiplicity of ways. Thus, it can make the AI become cyclically demented, like human Bipolar Disorder or Schizophrenic. THAT\u2019S FOR STARTS!! Many BRILLIANT TECHIES have Asperger\u2019s Syndrome and are BRILLIANT, But sociologically they could care LESS about humans and, if having an \u201cI\u2019ll write a virus bad day\u201d, introduce something unexpected on-the-fly into the software that creates a VERY NASTY MEAN AI! Governments like China who might want to do Whatever they well deem please could create, mod, or orchestrate All Kinda Robo-Naughts IF THEY Feel it suits them, no rules from outside their Kingdom need apply. Then you have the GREEDY ONES Above the Techies who set ABSURD TIMELINE Constraints to PUSH NEW TECHNOLOGY INTO PRODUCTION Well before it is System Tested\u2026 and And AND\u2026 SOME of the Technologies are sooo above what we can \u201cpredict\u201d ==> that inability to Predict An AWESOMESOMELY COMPLEX Scenario could create without intent a Scenario that makes Reality a place, where we Wish we could create a Fantasy to make the antidote in 1/2 hour like good old Doc McCoy could on Startrek,,, but in reality,, a mutating virus is often 3 steps ahead of its last antidote. There are MANY WAYS FOR A COMPLEX AI to become Dangerous,, never EVER EVER EVER ASSUME that the Money People and Big Dawgs of New Technology have your Safety and Security as their Prime Directive,, Nope,, don\u2019t do that! ",
            "date": "Answered February 21, 2019",
            "views": "40",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Roberto Vilar",
                "href": "/profile/Roberto-Vilar"
            },
            "answer_text": "To answer to the AI prospective, I will use some psychoanalytics perspectives. Human animals are what they are for two main reasons. Their incompleteness in front of nature (Lacan\u2019s followers described us as monkeys\u2019 foetus with reproductive abilities)The need to use words to explain/understand the emotions generated through our organs.So the next AI can be seen as a set of spreaded sensors and interfaces, passing informations directly from the external nature, to evolutive algorithms, and executing smart contracts, possibly within a superblockchain, to exerce feedback on the digital and real world. Could this system escape from human control? By definition, yes, as the multitude of logical nodes should prevent from human intervention. Would this system reach consciousness? If we consider fragility and incompletness as part of the process for consciousness, no, this super machine would not experience it. A super network will not feel the need for a face to face interaction with similar cyber-beings, as consciousness arise through this process, from the first glances in parents\u2019 hands. Could this network threaten life on earth? Definitely yes, as algorithms can spread agressive and destructive smart contracts through \u201cconnected things\u201d. So a super AI will expand cerebral abilities, as Atlas rockets reinforced human arm to throw objects in direction of the outer space. Not less, not more. Humanity will be much more shaken by the abscence of existence that quantics are finding, behind our sensorial perception. A proven absence of free will or the convinction that we will stay trapped in this planet for ever would deeply shake social structures too. Interconected AI could turn disruptive in those fields by solving more and more theorems connected with the irrational property of matter, space and time. Now at the end Homo Sapiens Sapiens will not extinguish his angst and satisfy his incompletude through relationships with artefacts. So as a baby bored by a new toy, he is already moving to transhumanism and conscience transfer, to avoid to face his real finite existential position within this universe. Reference in French, often for these subjects english web texts suffer some restrictions. \u00ab D\u00e8s les ann\u00e9es 1930, en se fondant sur les travaux d\u2019anatomie de son temps, Lacan d\u00e9fendait la th\u00e8se d\u2019une \u00ab pr\u00e9maturation sp\u00e9cifique de la naissance chez l\u2019homme \u00bb : tout se passe comme si l\u2019\u00eatre humain naissait pr\u00e9matur\u00e9ment. Il est fondamentalement inachev\u00e9, constitutivement d\u00e9ficient. Ainsi que l\u2019\u00e9crit en une formule frappante Louis Bolk, r\u00e9f\u00e9rence ch\u00e8re \u00e0 Lacan, \u00ab l\u2019homme est, du point de vue corporel, un f\u0153tus de primate parvenu \u00e0 maturit\u00e9 sexuelle \u00bb. \u00bb[1] Footnotes[1] N\u00e9ot\u00e9nie \u2014 Wikip\u00e9dia",
            "date": "Updated August 31, 2018",
            "views": "140",
            "upvotes": " Answer requested by Manfred Kramer"
        }
    ]
}