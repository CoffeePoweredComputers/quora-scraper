{
    "title": "What language(s) was Instagram written in? - Quora",
    "tags": [
        "Instagram (product)",
        "Language",
        "Programming Languages"
    ],
    "response": [
        {
            "author_info": {
                "name": "Isuranga Perera",
                "href": "/profile/Isuranga-Perera"
            },
            "answer_text": "Blog post by http://instagram-engineering.tum... What Powers Instagram: Hundreds of Instances, Dozens of Technologies One of the questions we always get asked at meet-ups and conversations with other engineers is, \u201cwhat\u2019s your stack?\u201d We thought it would be fun to give a sense of all the systems that power Instagram, at a high-level; you can look forward to more in-depth descriptions of some of these systems in the future. This is how our system has evolved in the just-over-1-year that we\u2019ve been live, and while there are parts we\u2019re always re-working, this is a glimpse of how a startup with a small engineering team can scale to our 14 million+ users in a little over a year. Our core principles when choosing a system are: Keep it very simpleDon\u2019t re-invent the wheelGo with proven and solid technologies when you canWe\u2019ll go from top to bottom: OS / Hosting We run Ubuntu Linux 11.04 (\u201cNatty Narwhal\u201d) on Amazon EC2. We\u2019ve found previous versions of Ubuntu had all sorts of unpredictable freezing episodes on EC2 under high traffic, but Natty has been solid. We\u2019ve only got 3 engineers, and our needs are still evolving, so self-hosting isn\u2019t an option we\u2019ve explored too deeply yet, though is something we may revisit in the future given the unparalleled growth in usage. Load Balancing Every request to Instagram servers goes through load balancing machines; we used to run 2 nginx machines and DNS Round-Robin between them. The downside of this approach is the time it takes for DNS to update in case one of the machines needs to get decomissioned. Recently, we moved to using Amazon\u2019s Elastic Load Balancer, with 3 NGINX instances behind it that can be swapped in and out (and are automatically taken out of rotation if they fail a health check). We also terminate our SSL at the ELB level, which lessens the CPU load on nginx. We use Amazon\u2019s Route53 for DNS, which they\u2019ve recently added a pretty good GUI tool for in the AWS console. Application Servers Next up comes the application servers that handle our requests. We run Djangoon Amazon High-CPU Extra-Large machines, and as our usage grows we\u2019ve gone from just a few of these machines to over 25 of them (luckily, this is one area that\u2019s easy to horizontally scale as they are stateless). We\u2019ve found that our particular work-load is very CPU-bound rather than memory-bound, so the High-CPU Extra-Large instance type provides the right balance of memory and CPU.We use http://gunicorn/Python WSGI HTTP Server for UNIX as our WSGI server; we used to use mod_wsgi and Apache, but found Gunicorn was much easier to configure, and less CPU-intensive. To run commands on many instances at once (like deploying code), we use Fabric, which recently added a useful parallel mode so that deploys take a matter of seconds. Data storage Most of our data (users, photo metadata, tags, etc) lives in PostgreSQL; we\u2019vepreviously written about how we shard across our different Postgres instances. Our main shard cluster involves 12 Quadruple Extra-Large memory instances (and twelve replicas in a different zone.) We\u2019ve found that Amazon\u2019s network disk system (EBS) doesn\u2019t support enough disk seeks per second, so having all of our working set in memory is extremely important. To get reasonable IO performance, we set up our EBS drives in a software RAID using mdadm. As a quick tip, we\u2019ve found that vmtouch is a fantastic tool for managing what data is in memory, especially when failing over from one machine to another where there is no active memory profile already. Here is the script we use to parse the output of a vmtouch run on one machine and print out the corresponding vmtouch command to run on another system to match its current memory status. All of our PostgreSQL instances run in a master-replica setup using Streaming Replication, and we use EBS snapshotting to take frequent backups of our systems. We use XFS as our file system, which lets us freeze & unfreeze the RAID arrays when snapshotting, in order to guarantee a consistent snapshot (our original inspiration came from ec2-consistent-snapshot. To get streaming replication started, our favorite tool is repmgr by the folks at 2ndQuadrant.To connect to our databases from our app servers, we made early on that had a huge impact on performance was using Pgbouncer to pool our connections to PostgreSQL. We found Christophe Pettus\u2019s blog to be a great resource for Django, PostgreSQL and Pgbouncer tips. The photos themselves go straight to Amazon S3, which currently stores several terabytes of photo data for us. We use Amazon CloudFront as our CDN, which helps with image load times from users around the world (like in Japan, our second most-popular country). We also use Redis extensively; it powers our main feed, our activity feed, our sessions system (here\u2019s our Django session backend), and other related systems. All of Redis\u2019 data needs to fit in memory, so we end up running several Quadruple Extra-Large Memory instances for Redis, too, and occasionally shard across a few Redis instances for any given subsystem. We run Redis in a master-replica setup, and have the replicas constantly saving the DB out to disk, and finally use EBS snapshots to backup those DB dumps (we found that dumping the DB on the master was too taxing). Since Redis allows writes to its replicas, it makes for very easy online failover to a new Redis machine, without requiring any downtime. For our geo-search API, we used PostgreSQL for many months, but once our Media entries were sharded, moved over to using Apache Solr. It has a simple JSON interface, so as far as our application is concerned, it\u2019s just another API to consume. Finally, like any modern Web service, we use Memcached for caching, and currently have 6 Memcached instances, which we connect to using pylibmc & libmemcached. Amazon has an Elastic Cache service they\u2019ve recently launched, but it\u2019s not any cheaper than running our instances, so we haven\u2019t pushed ourselves to switch quite yet. Task Queue & Push Notifications When a user decides to share out an Instagram photo to Twitter or Facebook, or when we need to notify one of our Real-time subscribers of a new photo posted, we push that task into Gearman, a task queue system originally written at Danga. Doing it asynchronously through the task queue means that media uploads can finish quickly, while the \u2018heavy lifting\u2019 can run in the background. We have about 200 workers (all written in Python) consuming the task queue at any given time, split between the services we share to. We also do our feed fan-out in Gearman, so posting is as responsive for a new user as it is for a user with many followers.For doing push notifications, the most cost-effective solution we found washttp://pyapns/https://github.com/samuraisam/py..., an open-source Twisted service that has handled over a billion push notifications for us, and has been rock-solid. Monitoring With 100+ instances, it\u2019s important to keep on top of what\u2019s going on across the board. We use Munin to graph metrics across all of our system, and also alert us if anything is outside of its normal range. We write a lot of custom Munin plugins, building on top of Python-Munin, to graph metrics that aren\u2019t system-level (for example, signups per minute, photos posted per second, etc). We use Pingdomfor external monitoring of the service, andPagerDuty for handling notifications and incidents.For Python error reporting, we use Sentry, an awesome open-source Django app written by the folks at Disqus. At any given time, we can sign-on and see what errors are happening across our system, in real time. You? If this description of our systems interests you, or if you\u2019re hopping up and down ready to tell us all the things you\u2019d change in the system, we\u2019d love to hear from you. We\u2019re looking for a DevOps person to join us and help us tame our EC2 instance herd. ",
            "date": "Answered December 21, 2016",
            "views": "265",
            "upvotes": " View 15 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Khush Manvar",
                    "user_href": "/profile/Khush-Manvar"
                },
                {
                    "user_id": "Jhonattan Mill\u00e1n",
                    "user_href": "/profile/Jhonattan-Mill\u00e1n-1"
                },
                {
                    "user_id": "Shayden Games",
                    "user_href": "/profile/Shayden-Games"
                },
                {
                    "user_id": "Lawrence Law",
                    "user_href": "/profile/Lawrence-Law-7"
                },
                {
                    "user_id": "Ayush Pandey",
                    "user_href": "/profile/Ayush-Pandey-304"
                },
                {
                    "user_id": "Andr\u00e9s Carvajal",
                    "user_href": "/profile/Andr\u00e9s-Carvajal"
                },
                {
                    "user_id": "VaiShnaVi LoKhanDe",
                    "user_href": "/profile/VaiShnaVi-LoKhanDe-18"
                },
                {
                    "user_id": "Sagar M R",
                    "user_href": "/profile/Sagar-M-R-1"
                },
                {
                    "user_id": "Aditya Anand Pandey",
                    "user_href": "/profile/Aditya-Anand-Pandey-1"
                },
                {
                    "user_id": "Kaveesha Baddage",
                    "user_href": "/profile/Kaveesha-Baddage"
                }
            ]
        },
        {
            "author_info": {
                "name": "Chetan Kashyap",
                "href": "/profile/Chetan-Kashyap"
            },
            "answer_text": "I just went through someone\u2019s(Sai Umesh\u2019s) answer to your question and so i thought of correcting that. So, i just want to make a thing clear. Instragram has 5 different front ends : android app,the iphone app, windows phone app, windows app and the web page. So, i think they use Python and strongly for their back end programming. The backend is everything that happens when you take an action. So when you sign in, you send your username and password to the server. The server is the backend. On that server, your credentials are checked against a database (another part of the backend). A response is sent back to the app saying whether you are logged in or not. This is the job of the backend. Same thing with the photos--once you hit \"share\", the photos and whatever caption you enter are uploaded to the server (backend). They're stored in the database (backend). When you or others view your photos, you send a request to the server (backend) to serve up whatever photos you want to see. So the backend in this example includes the servers, the database, and the programming that makes it all work together. This programming, which is done in a server-side language like Ruby on Rails, Python, PHP, or Node.js, handles your requests, performs actions against the database. If you build an iOS application which reads some data from the sensors on the devices and displays the data in an interesting way. That\u2019s front-end development. If your coding on saving those data in the servers , that would be back end. There are a lot of different front ends being used, the development team first developed it as an android app and web page was designed so that users can see their news feed in any web browser, then the team developed versions for both windows phone and pc, later they developed an iPhone app. In the back end they run Django on Amazon High-CPU Extra-Large machines. They use load balancing machines( nginx ) to process the requests OS used is ubuntu linux 11.04(as previous versions weren\u2019t that compatible to amazon ec2) . This is used to run on amazon ec2. For data storage and management, Postgre SQL is used. ",
            "date": "Answered July 15, 2017",
            "views": "204",
            "upvotes": " View 20 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Harsh Narwani",
                    "user_href": "/profile/Harsh-Narwani-3"
                },
                {
                    "user_id": "Vedic Yadav",
                    "user_href": "/profile/Vedic-Yadav-1"
                },
                {
                    "user_id": "Hardey Pandya",
                    "user_href": "/profile/Hardey-Pandya"
                },
                {
                    "user_id": "Rohith Nemeli",
                    "user_href": "/profile/Rohith-Nemeli"
                },
                {
                    "user_id": "Prajjwal Sharma",
                    "user_href": "/profile/Prajjwal-Sharma-33"
                },
                {
                    "user_id": "Gagan Mehra",
                    "user_href": "/profile/Gagan-Mehra-18"
                },
                {
                    "user_id": "Jojo Kys",
                    "user_href": "/profile/Jojo-Kys"
                },
                {
                    "user_id": "Alfas Hakeem",
                    "user_href": "/profile/Alfas-Hakeem"
                },
                {
                    "user_id": "Shriram Jugnake",
                    "user_href": "/profile/Shriram-Jugnake"
                },
                {
                    "user_id": "Niko Shervashidze",
                    "user_href": "/profile/Niko-Shervashidze"
                }
            ]
        }
    ]
}