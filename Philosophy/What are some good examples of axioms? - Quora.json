{
    "title": "What are some good examples of axioms? - Quora",
    "tags": [
        "Axioms (logic and mathematics)"
    ],
    "response": [
        {
            "author_info": {
                "name": "Franklin Parker",
                "href": "/profile/Franklin-Parker-2"
            },
            "answer_text": " Von-Neumann and Morganstern\u2019s axioms of Rational Economic Choice come to mind. Let [math]L, M, N[/math] represent choices (or choice sets). Any rational choice must be consistent with the following four axioms. 1. [math]L\\prec M, M\\prec L, [/math] or [math]L \\sim M[/math]. 2. [math] L \\prec M \\wedge M \\prec N \\Rightarrow L \\prec N[/math]. 3. [math]\\forall L\\preceq M \\preceq N, \\exists p \\in [0,1] : pL + (1-p)N \\sim M[/math]. 4. [math] L\\preceq M \\wedge p \\in [0,1], \\forall N: pL + (1-p)N \\preceq pM + (1-p)N[/math] IN ENGLISH. Axiom (1) is the axiom of completeness which says that for any choice, you can rank-order them by preference, and those preferences are complete\u2014there isn\u2019t an outcome you cannot rank-order. In other words, if I give you three possible outcomes: 1. you get an orange, 2. you get a cat, 3. you get nothing, then you should be able to order your preference of those outcomes, and that ordering shouldn\u2019t leave something out. Axiom (2) is the axiom of transitivity. If you prefer outcome M to outcome L, and you also prefer outcome N to outcome M, then you should prefer outcome N to outcome L. In other words, if I give you the three outcomes above and you tell me that you prefer the orange to the cat, and prefer the cat to nothing, then I can infer that you prefer the orange to nothing. Axiom (3) is the axiom of continuity, which expects some \u201ctipping point\u201d between your preference for things. In other words, for your most preferred outcome (N) and your least-preferred outcome (L), there must exist some point, p, which balances the two and makes you indifferent to your middle outcome (M). Let\u2019s say I give you the same choices we have been working with (orange, cat, nothing), and you tell me that your preferences are in this order, orange > cat > nothing, then I should be able to offer you some bundle of oranges and nothing to make you indecisive between that bundle and getting the cat. Axiom (4) is the axiom of independence. It expects you to be indifferent to random alternatives which are thrown in the mix. In other words, if you prefer M to L, then adding the same amount of N to any choice shouldn\u2019t change your choice. Keeping with our example (and order of preference), let\u2019s say I offer you a choice between two bundles: one has oranges and carrots, and the other has cats and carrots. This axiom says that your preferences will remain the same. Just because I randomly added carrots, you should still prefer the bundle that contains oranges because that is what you preferred before adding carrots.  WHAT DOES THIS MEAN?Turns out, these axioms form the basis of pretty much all economic theory. Because these axioms underlie utility theory (which is the study of how people make decisions), they percolate into the theory of the firm, macro economics, investment theory, portfolio theory, even marketing. Interestingly, however, there are numerous critiques of these axioms. As it turns out, people don\u2019t really behave in keeping with them. For example, it has been shown that Axiom (4) is violated regularly.[1][2] Not to mention, the utility formulations which draw from the axioms have been shown to be poor models of real-world behavior. There is no better exposition of the debate about how people should act and how they do act than what Nobel-laureate (and founder of Modern portfolio theory) Harry Markowitz wrote in his 1959 book Portfolio Selection (p. 219): it is possible for an individual to prefer an alternative inconsistent with the Expected Utility maxim. In each case the \u201cwrong\u201d alternative has a plausible appearance and is chosen by many persons questioned\u2026 The conclusion with Allais drew from his examples is that, since reasonable men choosing among simple alternatives contradict the expected utility maxim, this rule must be a poor one. The conclusion which this writer drew was that the individuals choosing the \u201cwrong\u201d alternative acted irrationally. This pretty much sums up the debate. Footnotes[1] L'Extension des Theories de l'Equilibre Economique General et du Rendement Social au Cas du Risque[2] http://www.its.caltech.edu/~camerer/Ec101/ProspectTheory.pdf",
            "date": "Answered October 15, 2018",
            "views": "63",
            "upvotes": " View 22 Upvoters",
            "upvoters": [
                {
                    "user_id": "David Joyce",
                    "user_href": "/profile/David-Joyce-11"
                },
                {
                    "user_id": "Nishant Jain",
                    "user_href": "/profile/Nishant-Jain-66"
                },
                {
                    "user_id": "Choi Joseph",
                    "user_href": "/profile/Choi-Joseph"
                },
                {
                    "user_id": "Jon Wayland",
                    "user_href": "/profile/Jon-Wayland"
                },
                {
                    "user_id": "Jonathan Hole",
                    "user_href": "/profile/Jonathan-Hole"
                },
                {
                    "user_id": "Yuriy Usanov",
                    "user_href": "/profile/Yuriy-Usanov"
                },
                {
                    "user_id": "Martin Silvertant",
                    "user_href": "/profile/Martin-Silvertant"
                },
                {
                    "user_id": "Bruno Saramago Monteiro",
                    "user_href": "/profile/Bruno-Saramago-Monteiro"
                },
                {
                    "user_id": "Jake Chateau",
                    "user_href": "/profile/Jacob-Chateau-1"
                },
                {
                    "user_id": "Nick Layon",
                    "user_href": "/profile/Nick-Layon"
                }
            ]
        },
        {
            "author_info": {
                "name": "Steven Tye Culbert",
                "href": "/profile/Steven-Tye-Culbert"
            },
            "answer_text": "First of all, an axiom is essentially irreducibly self-evident. That is, it must be accepted on its face. If a self-evident statement, mathematical or verbal, is not accepted as so, then even that axiomatic statement will to the single mind be considered non-axiomatic. For instance, modus ponens, if p then q, if q then p, is an abstraction of a self-evident pairing. I.e., if it\u2019s raining, things exposed to the rain get wet; things exposed to rain get wet if it\u2019s raining. . . Better: if something lives, it moves. Any definition of life will require the presence of movement. However, many things do not live but do move. Therefore, to contend that an old man is alive may not be true because he may be an old dead man. So, what axiom is undeniably true to every reasonable person? None. To one person, a corpse is dead; to another person, the corpse writhes with life. A husband dies; his widow speaks to him. She swears he visits her at night, his spirit. Is he dead to her? Of course not. Only his body is dead to her. He, himself, his spirit, lives. That the widow is deluded cannot be proved. Try as one might, the insane believe what they know. Axiom: What limits a zero vector must exist within a closed system. That sounds reasonable to me, but to other people it makes no sense. . . In traditional physics, closed systems contain certain stability that rocks back and forth: suns collapse, suns expand, holes of energy change color, a balloon contains air then the air goes out, air goes into the same deflated balloon. Axiom: Change is constant. Change is the only constant. Sounds good. A friend of mine, a famous war hero and physicist, claimed that some closed systems exist. I claimed to his face that a fallacy of traditional physics is the contention, the given that entropy occurs within a closed system. He was 97 years old. He squinted at me in disbelief and told me I was an idiot. I told him that no closed system exists. Again, he said I was an idiot. Then I asked him to give me and the other physicist listening to us argue one example of a closed system. A bomb, he said. If the bomb weren\u2019t closed, it would not behave predictably. I retorted that no encased explosive device has ever or will ever be perfectly contained. He laughed and told me that I could never get a job, thinking like that. . . We were sitting in a coffee shop. A human body asleep in a chair farted softly. ",
            "date": "Answered January 3, 2018",
            "views": "15",
            "upvotes": " View 5 Upvoters ",
            "upvoters": [
                {
                    "user_id": "Will Razen",
                    "user_href": "/profile/Will-Razen"
                },
                {
                    "user_id": "Mitchell Knott",
                    "user_href": "/profile/Mitchell-Knott-2"
                },
                {
                    "user_id": "Roland Benzon",
                    "user_href": "/profile/Roland-Benzon"
                },
                {
                    "user_id": "Esther June Subashini Stephen",
                    "user_href": "/profile/Esther-June-Subashini-Stephen"
                },
                {
                    "user_id": "Alan Smitty",
                    "user_href": "/profile/Alan-Smitty-1"
                }
            ]
        }
    ]
}