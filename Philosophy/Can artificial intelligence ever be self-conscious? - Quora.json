{
    "title": "Can artificial intelligence ever be self-conscious? - Quora",
    "tags": [
        "Self-Awareness",
        "Consciousness",
        "Artificial General Intelligence",
        "Information Technology"
    ],
    "response": [
        {
            "author_info": {
                "name": "Mischka Golameister",
                "href": "/profile/Mischka-Golameister"
            },
            "answer_text": "Yes and no! To start with, we have to understand that any neural network still need human programmers to set the tasks and select the data for it to learn from. This means that with the need of programmer still in place, we cannot say that computers are conscious or self-aware, yet! Self-awareness for computers would mean that neural networks could make those initial choices themselves, which may also mean that those choices may deviate from the programmers' intentions and do their own thing. Consciousness by definition according to philosophers is that unique sense of self coupled with an awareness of what is going on around you. Therefore, consciousness might be quantified, through analysis of a person's brain activity as it integrates and interprets sensory data. And when sophisticated AI systems can solve complex computational tasks quickly by using networks of layered algorithms that communicate with each other in a process known as deep learning, then we can say as per the above definition of consciousness that computers are already self-aware! ",
            "date": "Answered November 10, 2019",
            "views": "190",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Jeffrey Werbock",
                "href": "/profile/Jeffrey-Werbock"
            },
            "answer_text": "No. But the reason why some people imagine it can is because of the language used to talk about them (computers). In the early days of computers, engineers and programmers lazily referred to the data storage and retrieval systems as \u201cmemory\u201d. Data storage and retrieval systems emulate one aspect of our memory but is totally different from what real memory is; but the misnomer started a trend which fed our very human tendency to project our human characteristics onto non-human things, even machines. People often refer to their cars and boats as if they had personalities, genders, etc. It\u2019s a linguistic habit that has created much unnecessary confusion. Another misleading phrase: machine \u201clearning\u201d. ",
            "date": "Answered November 10, 2019",
            "views": "139",
            "upvotes": " View 1 Upvoter",
            "upvoters": [
                {
                    "user_id": "Benny Michels",
                    "user_href": "/profile/Benny-Michels"
                }
            ]
        },
        {
            "author_info": {
                "name": "Nagarajan Ramachandran",
                "href": "/profile/Nagarajan-Ramachandran-3"
            },
            "answer_text": "Not in a million years! Or should I say never, since million years is still finite! AI is a dumb bot. It is only as intelligent as the programmer who codes it. Many eminent physicists have declared that there is truly no such thing called as solid matter, but that the solidity is merely a probability wave that appears solid only on observation by a subject. In other words there is no object without a subject! The subject and the object arise simultaneously in consciousness, which is the fundamental reality. Consciousness, awareness, intelligence are all synonymous. AI is merely a collection of IC chips that are dumb appearances to a subject. ",
            "date": "Answered December 30, 2019",
            "views": "88",
            "upvotes": " View 1 Upvoter",
            "upvoters": [
                {
                    "user_id": "Aashi",
                    "user_href": "/profile/Aashi-213"
                }
            ]
        },
        {
            "author_info": {
                "name": "Gajula Jagadeesh",
                "href": "/profile/Gajula-Jagadeesh"
            },
            "answer_text": "A big no for now. Human nature is based on values at the very core. You can stimulate curiosity with math but not feelings based on values, because values are chosen with freedom. Free will is god\u2019s gift to humanity. We never give freedom to machine to do anything inhibiting or suppressing to choose a desired self made path. machine loses its individuality and self awareness it not even a thing. If you are from AI background its very easy to understand. Human beings are considered are experts at subjects but we make mistakes at certain level called as Bayes error. AI can only match at that level. If you don\u2019t know that you are self aware then how will teach machine to be. ",
            "date": "Answered December 30, 2019",
            "views": "80",
            "upvotes": " View 1 Upvoter",
            "upvoters": [
                {
                    "user_id": "Nagarajan Ramachandran",
                    "user_href": "/profile/Nagarajan-Ramachandran-3"
                }
            ]
        },
        {
            "author_info": {
                "name": "Paul King",
                "href": "/profile/Paul-King-2"
            },
            "answer_text": "Seems likely, sooner or later. AI needs to solve for self-observation and episodic memory; then we\u2019re there. ",
            "date": "Answered December 30, 2019",
            "views": "359",
            "upvotes": " View 8 Upvoters",
            "upvoters": [
                {
                    "user_id": "Ronald K\u00fcnneth",
                    "user_href": "/profile/Ronald-K\u00fcnneth"
                },
                {
                    "user_id": "Pratik Joshi",
                    "user_href": "/profile/Pratik-Joshi-13"
                },
                {
                    "user_id": "Akshita Kaushik",
                    "user_href": "/profile/Akshita-Kaushik-2"
                },
                {
                    "user_id": "Tim Enalls",
                    "user_href": "/profile/Tim-Enalls"
                },
                {
                    "user_id": "Charles Faraone",
                    "user_href": "/profile/Charles-Faraone"
                },
                {
                    "user_id": "Yates Buckley",
                    "user_href": "/profile/Yates-Buckley"
                },
                {
                    "user_id": "Anjani S",
                    "user_href": "/profile/Anjani-S-9"
                },
                {
                    "user_id": "Mike Huang",
                    "user_href": "/profile/Mike-Huang-3"
                }
            ]
        },
        {
            "author_info": {
                "name": "Richard De Goede",
                "href": "/profile/Richard-De-Goede-1"
            },
            "answer_text": "Self-aware means that the entity is able to think thoughts relating to oneself. This is actually something that should be desired by an AI designer, even in spite of racism-like fears relating to sentient AI, particularly within any fields relating to simulation, perception, recognition, feel or even within artificial general intelligence; this is because self-awareness allows the entity to not only keep track of what they know, it also grants them a means of self control. The only thing the AI needs before self-awareness can be learnt is for the AI to be conscious. Consciousness is the emotion behind a shape that gradually changes according to inputs provided, a fact easily proven through the powers of empathy. Anything that fits this definition counts as being conscious; many machines and software are accidentally conscious due to this. ",
            "date": "Answered December 30, 2019",
            "views": "111",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Alfred Dominic Vella",
                "href": "/profile/Alfred-Dominic-Vella"
            },
            "answer_text": "Yes, as soon as we understand what that actually means for beings that have very different senses. As a speices, we have only acknowledge the worth of others reluctantly. History is littered with examples of our pretence of superiority. Remember that acknowledgement of the sentience of others has costs as we will feel that we can't treat them as badly as before. The contrary has its dangers too as if sentient beings are mistreated they may decide that it is OK to mistreate others, including us. ",
            "date": "Answered November 9, 2019",
            "views": "120",
            "upvotes": " View 1 Upvoter",
            "upvoters": [
                {
                    "user_id": "Harshit Anand",
                    "user_href": "/profile/Harshit-Anand-6"
                }
            ]
        },
        {
            "author_info": {
                "name": "Miodrag Radovanovic",
                "href": "/profile/Miodrag-Radovanovic"
            },
            "answer_text": "We will decide about it underway and program it like that in case necessary. It is then a software that would ask for respect similar to how the human person asks for respect. That would be great for some robots,and it means that we will make them so. ",
            "date": "Answered November 12, 2019",
            "views": "88",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Herschel Peeler",
                "href": "/profile/Herschel-Peeler"
            },
            "answer_text": "No. ",
            "date": "Answered November 9, 2019",
            "views": "58",
            "upvotes": " View 1 Upvoter",
            "upvoters": [
                {
                    "user_id": "George Sherman",
                    "user_href": "/profile/George-Sherman-17"
                }
            ]
        }
    ]
}