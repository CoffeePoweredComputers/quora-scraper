{
    "title": "Is intelligence intelligent? - Quora",
    "tags": [
        "Artificial General Intelligence",
        "Smart People",
        "Intelligence",
        "Artificial Intelligence",
        "Philosophy"
    ],
    "response": [
        {
            "author_info": {
                "name": "Mathias Schmerling",
                "href": "/profile/Mathias-Schmerling"
            },
            "answer_text": "A brilliant question, I must say, going straight to the heart of matter. I\u2018m going to approach this from where it\u2018s most interesting and say: it might not be! Intelligence might not be intelligent. Clearly for this to make sense, we would have to grant that the term \u201eintelligence\u201c doesn\u2019t necessarily mean the very human thing we most easily associate with it. Personally, I often catch myself doing exactly this: every time I watch a nature documentary telling me about some of ways species solve the problems their ecological niches present, my go-to reaction is to say: \u201eOh, that\u2018s clever!\u201c Of course, in many or even most cases, these species don\u2018t solve challenges to their survival by using \u201cintelligence\u201d, that is \u2026 well, let\u2018s call it cognition for the duration of this text. So, why am I willing to call them \u201cclever\u201d? Should we maybe widen our perspective a bit, imagine a new definition of intelligence? For this to be worthwhile, a new definition should satisfy some criteria. It should really be wider, not different, in that it should contain the original definition as a special case. And it should have something to offer; it should enable us to conceptualize some things that were hard to conceptualize before. Examples that might motivate this approach are plenty and they show that once you allow yourself to widen your perspective, interesting things start to happen: - Different levels of organization: Individual versus collective (swarm) intelligence. Ant colonies and the like. Should we call them intelligent? - Embodied cognition and morphological computation: Making tasks easier by the physical properties of a system. Best example is grasping, which, as it turns out, is really hard. In humans, a lot of the challenge is already solved by the \u201cdesign\u201d of our hands. Our fingertips are soft and slightly adhesive such that grasping doesn\u2018t require motor control as precise as hands made of solid material would. Material design is actually relevant for building robots as evidenced by the \u201ecoffee grabber\u201c: Universal Robot Gripper and Top-Down Grasp - Failures (x4). Soft robotics is the name of game. - Simplicity versus complexity: are simpler (non-cognitive) solutions to a problem smarter solutions? Examples are drones that are collision-resistant instead of obstacle avoiding (which requires a lot of computation) Flyability presentation - Elios, the collision-tolerant drone for industrial inspection. They\u2018re inspired by flies, I think, which also don\u2018t mind bumping into stuff all the time. - Parasitation of cognitive species by non-cognitive species: explained in this video: Eric Weinstein: Artificial Outelligence - AI that Evolves & Self-Replicates | AI Podcast Clips - Different time scales: species develop survival strategies within an individual\u2018s lifetime (i.e. through development and through learning) and across generations through natural selection. Is natural selection an intelligent algorithm? Trying to distill these examples into a wider definition of intelligence, it\u2018s probably something like \u2013 that which benefits survival. I personally like this view, since it arguably contains cognition as a special case, and it clears up some problems that might arise in the quest for Artificial Intelligence. Imagine two competing strategies to building a grasping robot, one of which is a state-of-the-art, computationally expensive machine learning algorithm, very \u201cintelligent\u201d by our measure of cognition, that\u2019s running on a robot with hands made of a solid material. Any grasping attempt needs to be very tightly controlled and the algorithm barely manages. The competing algorithm is very simple by comparison, maybe it\u2019s even evolutionary, but the robot it\u2019s running on uses soft robotic hands, designed to be able to grasp with minimal computational effort and high error tolerance. As soon as space or energy constraints start to matter, it is conceivable the latter robot would outcompete the first, the researchers building it losing interest, the company selling it going bankrupt. In the end, all future AIs might descend from the simpler model. How should we think about this failure? If intelligence is cognition, the first robot should have been it. In no way should this be seen a trivializing human cognitive ability, however. Rather, it opens up the question of which problems cognition is an intelligent solution for. In this view, cognition is an investment, not an achievement. Sometimes it\u2018s simply overkill. Natural selection treats cognition, \u201cintelligence\u201d as we tend to think about it, dispassionately. What a detour! Anyway, I went through all this trouble to be able to rephrase the original question in an interesting way. Here\u2019s what I came up with: Does human cognitive ability benefit the continuation of the human line of descent or not? Will it count as a hit or a miss in the evolutionary algorithm that\u2018s currently running on this planet? And the answer is not clear at all! Obviously, almost by definition, it must have been beneficial so far. But how far it will take us is very difficult to assess. On the one hand, cognition makes us uniquely adaptable and has enabled us to extend our habitat beyond the confines of a single ecological niche, us now occupying spaces all around the planet. On the other hand, thanks to our cognition, we now have all these tools of global impact at our disposal and some of them have the potential to undermine our very existence. At the same time, I worry that our collective \u201cintelligence\u201d, our community-building does not function on the global scale necessary to safeguard these tools. Come to think of it, it might just be that human cognition puts us in an uncanny valley of intelligence: smart enough to take control of the entire planet and to look out into the universe but not quite able to form the global community necessary to ensure our continued existence. How tragic that would be. With this in mind, I sometimes feel we have it all wrong when looking up to those of us who promise to take us to Mars, and that we should really be looking at those of us who bridge the gaps between us, who have moral clarity and a vision to offer of what a global community might look like. ",
            "date": "Answered September 15, 2019",
            "views": "141",
            "upvotes": "0"
        },
        {
            "author_info": {
                "name": "Alfred Dominic Vella",
                "href": "/profile/Alfred-Dominic-Vella"
            },
            "answer_text": "Who knows? We have a vague idea of intelligence gleaned from observation mainly of ourselves but have no idea what the necessary and sufficient conditions for it are. We might, as perhaps most do, expect it to be corporeal but how would we be able to tell if it were not? At present we are at the beginning of exploring the possibilities and it is likely to take a great deal of time before much real progress is made. ",
            "date": "Answered September 2, 2019",
            "views": "37",
            "upvotes": " View 1 Upvoter",
            "upvoters": [
                {
                    "user_id": "Nelson Vidinha",
                    "user_href": "/profile/Nelson-Vidinha"
                }
            ]
        }
    ]
}